
---
categories: äººå·¥æ™ºèƒ½
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*UTIFLGV3Wx0qNThJrJ8UhA.png
date: '2024-08-15 16:09:21'
tags:
  - RAG
  - Streamlit
  - Langchain
title: å®éªŒ 3å®ç° RAG æ„å»ºä¸å¤šä¸ª PDF èŠå¤©åº”ç”¨

---


ä½¿ç”¨ Streamlitã€Langchain å’Œ OpenAI

> è¿™æ˜¯æ–‡ç«  **â€œä¸ PDF èŠå¤©â€** çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œå‘å¸ƒåœ¨[**â€œä¸ä¸€åˆ‡èŠå¤©â€**](https://github.com/S0NM/chat-with-everything)ç³»åˆ—ä¸­ã€‚è¿™éƒ¨åˆ†å°†é‡ç‚¹ä»‹ç»å¦‚ä½•ä½¿ç”¨ RAG æ„å»ºä¸€ä¸ªæ”¯æŒå¤šä¸ª PDF çš„èŠå¤©åº”ç”¨ã€‚

> å¯¹äºé‚£äº›ä¸å¤ªäº†è§£çš„äººï¼Œ**â€œä¸ä¸€åˆ‡èŠå¤©â€**ç³»åˆ—ä¸“æ³¨äºä¸ºæ‚¨æä¾›æ„å»º LLM åº”ç”¨ç¨‹åºçš„æŠ€æœ¯çŸ¥è¯†å’ŒæŠ€å·§ã€‚æˆ‘åˆ›å»ºçš„æ‰€æœ‰åº”ç”¨ç¨‹åºéƒ½ä½¿ç”¨æµè¡Œçš„æ¡†æ¶ï¼šStreamlitã€Langchain å’Œ OpenAIï¼ˆLLM æ¨¡å‹ï¼‰ã€‚

> æ‚¨å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°â€œä¸ä¸€åˆ‡èŠå¤©â€ç³»åˆ—ï¼š[æˆ‘çš„ GitHub](https://github.com/S0NM/chat-with-everything)

## éš¾åº¦ç­‰çº§ï¼šä¸­çº§ ğŸ–ï¸ğŸ–ï¸



## æœ¬æ–‡å°†è¦æ¶µç›–çš„ä¸»è¦å†…å®¹ï¼š

1. ä¸ºä»€ä¹ˆ RAG é‡è¦ï¼Ÿ
2. RAG å®é™…æ˜¯å¦‚ä½•å·¥ä½œçš„
3. åº”ç”¨ RAG æ„å»ºä¸€ä¸ªâ€œä¸å¤šä¸ª PDF èŠå¤©â€çš„åº”ç”¨
4. æ¼”ç¤ºï¼ˆå¯¹äºé‚£äº›æƒ³å…ˆçœ‹åˆ°ç»“æœä»¥è·å¾—åŠ¨åŠ›çš„äººã€‚ï¼‰

# 1. ä¸ºä»€ä¹ˆ RAG é‡è¦ï¼Ÿ

åœ¨ä½¿ç”¨åƒ GPTã€Claudeã€BERT ç­‰ LLM æ¨¡å‹æ—¶ï¼Œæ‚¨å¯èƒ½é‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š

* æ¨¡å‹è™šæ„ä¿¡æ¯å¹¶ç”Ÿæˆä¸çœŸå®çš„ç­”æ¡ˆ **(å¹»è§‰æ•ˆåº”)**
* æ‚¨å¸Œæœ›æ¨¡å‹ **åœ¨æ‚¨è‡ªå·±çš„æ•°æ®æºä¸Šè¿è¡Œ**ï¼Œä»æ–‡æœ¬æ•°æ®ï¼ˆpdfã€doc ç­‰ï¼‰åˆ°å„ç§ç±»å‹çš„åª’ä½“æ•°æ®ï¼ˆè§†é¢‘ã€éŸ³é¢‘ã€ç…§ç‰‡ç­‰ï¼‰
* æœ‰æ—¶ï¼Œæ‚¨å¤„ç†éå¸¸é•¿çš„å†…å®¹ï¼Œå¯¼è‡´ **æ˜‚è´µçš„å¤„ç†æˆæœ¬** æˆ–æ‚¨çš„è´¦æˆ·ç®€å•åœ°è¢«å°é” 1-2 å°æ—¶ï¼ˆå½±å“æ‚¨çš„ç”Ÿäº§åŠ›ï¼‰

å¦‚æœæ‚¨å¯¹ä¸Šè¿°é—®é¢˜æ„ŸåŒèº«å—ï¼Œæ˜¯æ—¶å€™äº†è§£ RAG äº†ã€‚

## ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

**RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)** æ˜¯ä¸€ç§é€šè¿‡ä»å¤–éƒ¨èµ„æºè·å–äº‹å®æ¥æé«˜ç”Ÿæˆ AI æ¨¡å‹å‡†ç¡®æ€§å’Œå¯é æ€§çš„æŠ€æœ¯ã€‚RAG æ˜¯ä¸€ç§é‡è¦çš„æŠ€æœ¯ï¼Œå› ä¸ºï¼š

* **å‡ ä¹æ¯ä¸ª LLM** éƒ½å¯ä»¥ä½¿ç”¨ RAG è¿æ¥å‡ ä¹ä»»ä½•å¤–éƒ¨èµ„æºã€‚
* **RAG ä½¿æ‚¨çš„åº”ç”¨ç¨‹åºå¯¹æˆ‘ä»¬çš„ç”¨æˆ·æ›´å¯é ï¼ˆâ€œä¿¡ä»»â€ï¼‰ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸º RAG ä¸ºæ¨¡å‹æä¾›äº†å¯ä»¥å¼•ç”¨çš„æ¥æºï¼Œå°±åƒç ”ç©¶è®ºæ–‡ä¸­çš„è„šæ³¨ä¸€æ ·ï¼Œå› æ­¤ç”¨æˆ·å¯ä»¥æ£€æŸ¥ä»»ä½•å£°æ˜ã€‚è¿™å»ºç«‹äº†ä¿¡ä»»ã€‚**
* **å‡å°‘æ¨¡å‹é”™è¯¯çŒœæµ‹çš„å¯èƒ½æ€§**ï¼Œè¿™ç§ç°è±¡æœ‰æ—¶ç§°ä¸ºå¹»è§‰ã€‚
* æœ€åï¼ŒRAG ä½¿å¾—è¿™ç§æ–¹æ³• **æ¯”ä½¿ç”¨é¢å¤–æ•°æ®é›†é‡æ–°è®­ç»ƒæ¨¡å‹æ›´å¿«ä¸”æˆæœ¬æ›´ä½**ã€‚å¹¶ä¸”å®ƒå…è®¸ç”¨æˆ·åŠ¨æ€æ›´æ¢æ–°çš„æ¥æºã€‚

# 2. RAG å®é™…å·¥ä½œåŸç†

ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼Œæ•´ä¸ª RAG è¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

* **é˜¶æ®µ 1ï¼ˆé¢„å¤„ç†ï¼‰ï¼š** å°†å¤–éƒ¨æºåŠ è½½åˆ°æˆ‘ä»¬çš„ç³»ç»Ÿä¸­
* **é˜¶æ®µ 2ï¼ˆæ¨ç†ï¼‰ï¼š** åœ¨ LLM çš„æ”¯æŒä¸‹ä¸ºç”¨æˆ·çš„æŸ¥è¯¢ç”Ÿæˆç­”æ¡ˆ

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*ebOb_Y5DckOhw9wA_9fnHw.png)

è®©æˆ‘ä»¬æ·±å…¥äº†è§£è¿™ä¸¤ä¸ªé˜¶æ®µ

**é˜¶æ®µ 1ï¼šé¢„å¤„ç†é˜¶æ®µ**

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*g0EDp-JlQWgygJzs064vzw.png)

**1. ä»å¤–éƒ¨æºåŠ è½½æ•°æ®åˆ°æ–‡æœ¬ï¼š** è¿™ä¸ªè¿‡ç¨‹åœ¨ langchain æ¡†æ¶çš„æ”¯æŒä¸‹å¾ˆå®¹æ˜“å®Œæˆã€‚

* åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä½¿ç”¨ **PyPDFLoader** ä» PDF æ–‡ä»¶åŠ è½½æ•°æ®
* åœ¨å®è·µä¸­ï¼Œæˆ‘è¿˜ä½¿ç”¨å…¶ä»–æ–‡æ¡£åŠ è½½å™¨ä» YouTubeã€CSVã€Confluence ç­‰åŠ è½½æ•°æ®
* [ä½ å¯ä»¥è®¿é—® langchain å®˜æ–¹ç½‘ç«™](https://python.langchain.com/v0.2/docs/integrations/document_loaders/) è·å–æ‰€æœ‰æ–‡æ¡£åŠ è½½å™¨çš„åˆ—è¡¨

**2. å°†æ–‡æœ¬è½¬æ¢ä¸ºå—ï¼š** å°†æ–‡æœ¬æ‹†åˆ†ä¸ºå°å—ï¼Œä»¥ä¼˜åŒ–ä¿¡æ¯çš„å¤„ç†ã€å­˜å‚¨å’Œæ£€ç´¢ï¼ŒåŒæ—¶æé«˜ AI ç³»ç»Ÿçš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚

**3. å°†å—åµŒå…¥å‘é‡æ•°æ®åº“ï¼š** å‘é‡æ•°æ®åº“è¢«è®¤ä¸ºæ˜¯ RAG å®ç°å †æ ˆä¸­æœ€å¸¸è§çš„æ–¹å¼ï¼ˆåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä¹Ÿé€‰æ‹©äº†ä¸€ä¸ªå¯ä»¥è½»æ¾åœ¨æœ¬åœ°ç£ç›˜ä¸Šè¿è¡Œçš„å‘é‡æ•°æ®åº“ï¼Œå³ Chromaï¼‰ã€‚é€‰æ‹©æœ€ä½³å‘é‡æ•°æ®åº“çš„å†…å®¹åœ¨æœ¬æ–‡ä¸­æœªæ¶‰åŠã€‚å¦‚æœä½ æƒ³æ·±å…¥äº†è§£è¿™ä¸ªä¸»é¢˜ï¼Œ[***è¯·æŸ¥çœ‹ SuperLinked çš„åˆ—è¡¨***](https://superlinked.com/vector-db-comparison?via=topaitools)***ã€‚***

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RbXFm3XsVRTVqPDvwTWB8g.png)

**é˜¶æ®µ 2ï¼šæ¨ç†è¿è¡Œæ—¶é˜¶æ®µ**

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*bHYLb-naJkzApseh8hB9mQ.png)

**1. è¾“å…¥æŸ¥è¯¢ï¼ˆé—®é¢˜ï¼‰ï¼š** è¾“å…¥æŸ¥è¯¢çš„ç”¨æˆ·éœ€è¦å¾—åˆ°å›ç­”æˆ–å¤„ç†ã€‚

**2. åµŒå…¥æŸ¥è¯¢ï¼š** ä½¿ç”¨åµŒå…¥æ¨¡å‹å°†æŸ¥è¯¢è½¬æ¢ä¸ºåµŒå…¥ã€‚

**3. ä¿¡æ¯æ£€ç´¢ï¼š** ä½¿ç”¨æŸ¥è¯¢çš„å‘é‡è¡¨ç¤ºä»åŒ…å«åµŒå…¥æ–‡æœ¬çš„å¤§å‹æ•°æ®åº“ä¸­æŸ¥æ‰¾ç›¸å…³æ–‡æœ¬ã€‚

**4. æ–‡æœ¬ç”Ÿæˆå™¨ï¼š** æå–çš„æ–‡æœ¬å°†ä¸åŸå§‹æŸ¥è¯¢ä¸€èµ·ç”¨äºç”Ÿæˆæ–°çš„ç­”æ¡ˆæˆ–æ–‡æœ¬ã€‚ç”Ÿæˆå™¨ï¼ˆé€šå¸¸æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼‰å°†ç»“åˆè¿™äº›æ–‡æœ¬æ®µè½ä¸­çš„ä¿¡æ¯ç”Ÿæˆåé¦ˆã€‚

**5. è¾“å‡ºï¼ˆç­”æ¡ˆï¼‰ï¼š** åˆ›å»ºçš„æ–‡æœ¬å°†ä½œä¸ºå®Œæ•´ç­”æ¡ˆè¿”å›ç»™ç”¨æˆ·ã€‚

# 3. åº”ç”¨ RAG æ„å»ºâ€œä¸å¤šä¸ª PDF èŠå¤©â€åº”ç”¨

ä¸€æ—¦ä½ äº†è§£äº† RAG çš„å·¥ä½œåŸç†ï¼Œå°±è¯¥å’Œæˆ‘ä¸€èµ·æ„å»ºä¸€ä¸ªâ€œä¸å¤šä¸ª PDF èŠå¤©â€çš„åº”ç”¨äº†ã€‚å¹¶çœ‹çœ‹æˆ‘å¦‚ä½•å°† RAG åº”ç”¨åˆ°å®é™…åº”ç”¨ä¸­ã€‚

## è®¾ç½®

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…æ‰€æœ‰åŒ…


```python
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from langchain_community.vectorstores import Chroma
import chromadb
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains.retrieval import create_retrieval_chain
```
å°† OPENAI\_API\_KEY æ›¿æ¢ä¸ºæ‚¨è‡ªå·±çš„å¯†é’¥ï¼Œåœ¨ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä½¿ç”¨äº† streamlit secretï¼š


```python
# Replace it with your OPENAI API KEY if you use streamlit secrets
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
```
åœ¨ **ChromaDB** ä¸­åˆ›å»ºåä¸º **â€œchat-with-pdfâ€** çš„é›†åˆ


```python
# Load Vector datasse
native_db = chromadb.PersistentClient("./chroma_db")
db = Chroma(client=native_db, collection_name="chat-with-pdf", embedding_function=OpenAIEmbeddings())
```
ä¸ºäº†ä¸é›†åˆä¸€èµ·å·¥ä½œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å‡½æ•° **get\_collection**


```python
@st.cache_resource
def get_collection():
    print("DEBUG: call get_collection()")
    collection = None
    try:
        # Delete all documents
        native_db.delete_collection("chat-with-pdf")
    except:
        pass
    finally:
        collection = native_db.get_or_create_collection("chat-with-pdf", embedding_function=OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY))
    return collection
```

## é˜¶æ®µ 1ï¼šé¢„å¤„ç†é˜¶æ®µ

å½“ç”¨æˆ·ä¸Šä¼ ä¸€äº›æ–°æ–‡ä»¶æ—¶ï¼š

* åŠ è½½æ‰€æœ‰æ–°ä¸Šä¼ çš„æ–‡ä»¶
* å°†å…¶å†…å®¹æ‹†åˆ†ä¸ºå—
* å°†å—åµŒå…¥åˆ° ChromaDB ä¸­ï¼Œå¹¶ä¿å­˜åˆ° ChromaDB


```python
# Load, transform and embed new files into Vector Database
def add_files(uploaded_files):
    collection = get_collection()

    # old_filenames: contains a list of names of files being used
    # uploaded_filenames: contains a list of names of uploaded files
    old_filenames = st.session_state.old_filenames
    uploaded_filename = [file.name for file in uploaded_files]
    new_files = [file for file in uploaded_files if file.name not in old_filenames]

    for file in new_files:
        # Step 1: load uploaded file
        temp_file = f"./temp/{file.name}.pdf"
        with open(temp_file, "wb") as f:
            f.write(file.getvalue())
        loader = PyPDFLoader(temp_file)
        pages = loader.load()

        # Step 2: split content in to chunks
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        chunks = text_splitter.split_documents(pages)

        # Step 3: embed chunks into Vector Store
        # collection.add(ids=file.name,documents=chunks)
        for index, chunk in enumerate(chunks):
            collection.upsert(
                ids=[chunk.metadata.get("source") + str(index)], metadatas=chunk.metadata,
                documents=chunk.page_content
            )
```
å¦åˆ™ï¼Œå½“ç”¨æˆ·ä»åˆ—è¡¨ä¸­åˆ é™¤æ–‡ä»¶æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åˆ é™¤æ‰€æœ‰ç›¸å…³çš„å—


```python
# Remove all relevant chunks of the removed files
def remove_files(uploaded_files):
    collection = get_collection()

    # old_filenames: contains a list of names of files being used
    # uploaded_filenames: contains a list of names of uploaded files
    old_filenames = st.session_state.old_filenames
    uploaded_filename = [file.name for file in uploaded_files]

    # Step 1: Get the list of file that was removed from upload files
    deleted_filenames = [name for name in old_filenames if name not in uploaded_filename]

    # Step 2: Remove all relevant chunks of the removed files
    if len(deleted_filenames) > 0:
        all_chunks = collection.get()

        ids = all_chunks["ids"]
        metadatas = all_chunks["metadatas"]

        if len(metadatas) > 0:
            deleted_ids = []
            for name in deleted_filenames:
                for index, metadata in enumerate(metadatas):
                    if metadata['source'] == f"./temp/{name}.pdf":
                        deleted_ids.append(ids[index])
            collection.delete(ids=deleted_ids)
```
å°†ä¸¤ä¸ªæ–¹æ³•åˆå¹¶ä¸ºä¸€ä¸ªå‡½æ•°


```python
# Return chunks after having any change in the file list
def refresh_chunks(uploaded_files):
    # old_filenames: contains a list of names of files being used
    # uploaded_filenames: contains a list of names of uploaded files
    old_filenames = st.session_state.old_filenames
    uploaded_filename = [file.name for file in uploaded_files]

    if len(old_filenames) < len(uploaded_filename):
        add_files(uploaded_files)
    elif len(old_filenames) > len(uploaded_filename):
        remove_files(uploaded_files)

    # Step 3: Save the state
    st.session_state.old_filenames = uploaded_filename
```

## ç¬¬2é˜¶æ®µï¼šæ¨ç†è¿è¡Œæ—¶é˜¶æ®µ

* åˆ›å»ºä¸€ä¸ªä¸ChromaDBåä½œçš„æ£€ç´¢å™¨ã€‚æ£€ç´¢å™¨æ˜¯ä¸€ä¸ªæ¥å£ï¼Œèƒ½å¤Ÿæ ¹æ®éç»“æ„åŒ–æŸ¥è¯¢è¿”å›æ–‡æ¡£ã€‚
* åˆ›å»ºä¸€ä¸ªé“¾æ¡å°†æ‰€æœ‰å†…å®¹è¿æ¥åœ¨ä¸€èµ·


```python
# Init langchain
llm = ChatOpenAI(api_key=OPENAI_API_KEY)
prompt = ChatPromptTemplate.from_template("""
Based on the provided context only, find the best answer for my question. Format the answer in markdown format
<context>
{context}
</context>
Question:{input}
""")
document_chain = create_stuff_documents_chain(llm, prompt)
retriever = db.as_retriever()
retriever_chain = create_retrieval_chain(retriever, document_chain)
```
æ¯å½“ä½ æƒ³ä½¿ç”¨ **retriever\_chain** æ—¶ï¼Œå¯ä»¥è°ƒç”¨ **invoke.** ä¾‹å¦‚ï¼š


```python
response = retriever_chain.invoke({"input": "How to create a prompt for a new digital product"})
```
æœ€ç»ˆç»“æœï¼š

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vwqWul8Fdbl_zErRRgMl3Q.png)

# 4. å±•ç¤ºæ¡ˆä¾‹

è§†é¢‘æ¼”ç¤ºï¼š

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wk8fVYUBfsgDWAMDGrxcMg.gif)

# å¥–åŠ± ğŸ

æ‚¨å¯ä»¥è½»æ¾åœ°ä½¿ç”¨ RAG æœç´¢å®ç”¨ç¤ºä¾‹ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªæœ‰è¶£çš„ä¾‹å­ï¼Œå±•ç¤ºå¦‚ä½•åœ¨æ–‡æœ¬åˆ° SQL ä¸­ä½¿ç”¨ RAGï¼š**VannaAI**

**VannaAI** åœ¨æˆ‘æ’°å†™æœ¬æ–‡æ—¶æ‹¥æœ‰è¶…è¿‡ 9k çš„æ˜Ÿæ ‡å’Œ 658 ä¸ªåˆ†æ”¯ã€‚è¯¦ç»†ä¿¡æ¯å¯ä»¥åœ¨ [è¿™é‡Œ](https://vanna.ai/docs/) æ‰¾åˆ° [.](https://vanna.ai/docs/.) VannaAI æ­£åœ¨å°† RAG åº”ç”¨äºä¸¤ä»¶äº‹æƒ…ï¼š

* ä½¿ç”¨æ£€ç´¢å¢å¼ºæ¥å¸®åŠ©æ‚¨ä½¿ç”¨ LLM ç”Ÿæˆå‡†ç¡®çš„ SQL æŸ¥è¯¢ï¼Œä»¥ä¾¿æŸ¥è¯¢æ‚¨çš„æ•°æ®åº“ã€‚
* æ‚¨å¯ä»¥åœ¨è‡ªå·±çš„æ•°æ®ä¸Šè®­ç»ƒ RAG â€œæ¨¡å‹â€ï¼Œç„¶åæå‡ºé—®é¢˜ï¼Œè¿™å°†è¿”å›å¯ä»¥è®¾ç½®ä¸ºè‡ªåŠ¨åœ¨æ‚¨çš„æ•°æ®åº“ä¸Šè¿è¡Œçš„ SQL æŸ¥è¯¢ã€‚â€

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*g66Dw6RvzIBSuf9lylLn_A.png)

# åœ¨ä½ ç¦»å¼€ä¹‹å‰ï¼ğŸ¤Ÿ

å¦‚æœä½ è§‰å¾—è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©ï¼Œå¹¶å¸Œæœ›è¡¨ç¤ºæ”¯æŒï¼Œ**è¯·ä¸ºæˆ‘çš„æ–‡ç« é¼“æŒ 10 æ¬¡ã€‚** ğŸ‘ è¿™çœŸçš„ä¼šæ¿€åŠ±æˆ‘ï¼Œå¹¶å°†è¿™ç¯‡æ–‡ç« æ¨èç»™æ›´å¤šäººã€‚
