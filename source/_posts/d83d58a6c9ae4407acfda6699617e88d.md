
---
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*c-6YY9rmiJyu_3V-5Fsp_w.png
date: '2024-05-12 05:08:25'
tags:
  - 自适应RAG
  - RQ-RAG
  - 查询优化
title: 高级RAG 11查询分类与优化

---


## 自适应RAG与RQ-RAG的原理、代码解析及洞察

尽管传统RAG技术能缓解LLM回答的不准确性，但它并未对初始查询进行任何改进。这一点在图1的红框中有所体现。



这种方法可能带来一些潜在问题，例如：

* 该系统可能消耗过多计算资源来处理简单查询。
* 对于复杂查询，仅用原始查询进行检索往往无法收集足够信息。
* 对于可能有多个答案的模糊查询，使用原始查询进行信息检索显得不足。

本文将介绍两种高级解决方案：查询分类与查询细化。两者均通过小型模型的训练展现出改进效果。最后，文章将探讨从这两种算法中获得的洞察与思考。

# 自适应RAG：通过问题复杂度学习适应检索增强型大型语言模型

## 总体流程

Adaptive-RAG 引入了一种新的自适应框架。如图 2 所示，它根据查询的复杂度，从最简单到最复杂，动态选择最适合 LLM 的策略。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*3p6CBhYn-dMVnC27.png)

图 2 (A) 表示单步方法，首先检索相关文档，然后生成答案。然而，这种方法对于需要多步推理的复杂查询可能不够准确。

图 2 (B) 象征多步过程，涉及迭代文档检索和生成中间响应。尽管有效，但对于简单查询来说效率低下，因为它需要多次访问 LLM 和检索器。

图 2 (C) 是**一种自适应方法**，使用精心构建的分类器确定查询复杂度。这增强了为 LLM 检索选择最合适策略的能力，可能包括迭代、单步甚至无需检索的方法。

为了更直观地理解 Adaptive-RAG 过程，我们将结合代码进行解释。目前有四个版本的代码：[官方版本](https://github.com/starsuzi/Adaptive-RAG)、[Langchain 版本](https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_adaptive_rag_cohere.ipynb)、[LlamaIndex 版本](https://github.com/mistralai/cookbook/blob/e200507fba4e3404564f9249b345c89f83d73a10/third_party/LlamaIndex/Adaptive_RAG.ipynb) 和 [Cohere 版本](https://github.com/cohere-ai/notebooks/blob/main/notebooks/react_agent_adaptive_rag_cohere.ipynb)。我们将使用 LlamaIndex 版本进行解释。

详细信息请参阅此 [Jupyter Notebook](https://github.com/mistralai/cookbook/blob/e200507fba4e3404564f9249b345c89f83d73a10/third_party/LlamaIndex/Adaptive_RAG.ipynb)。代码较长，这里仅讨论关键部分。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*XnBKT2Y7uvHtE9_1.png)

代码的运行取决于查询的复杂度，相应调用不同的工具：

* 对于复杂查询：使用多个工具。这些工具需要来自多个文档的上下文，如图 3 右上所示。
* 对于简单查询：使用单一工具，需要来自单个文档的上下文，如图 3 左上所示。
* 对于直接查询：直接使用 LLM 提供答案，如图 3 底部所示。

如图 2 (C) 所示，工具的选择通过分类器进行。与原论文不同，这里使用的分类器未经训练，而是直接利用现有的 LLM，如图 4 所示。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*rqZyxqUyqzOBThgT.png)

## 分类器的构建

尽管LlamaIndex代码中不包含分类器训练过程，但理解分类器的构建过程对于我们进一步开发至关重要。

**数据集的构建**

一个关键挑战是缺乏用于查询-复杂度对的标注数据集。如何解决这一问题？Adaptive-RAG采用两种特定策略来自动构建训练数据集。

[Adaptive-RAG提供的数据集](https://github.com/starsuzi/Adaptive-RAG/blob/0c88670af8707667eb5c1163151bb5ce61b14acb/data.tar.gz)显示，分类器训练数据的标注基于公开标注的QA数据集。

有两种策略：

* 对于收集的问题，如果最简单的非检索方法生成了正确答案，则其对应查询的标签标记为‘`**A**`’。同样，通过单步方法正确回答的查询标记为‘`**B**`’，而通过多步方法正确回答的查询标记为‘`**C**`’。值得一提的是，更简单的模型被赋予更高优先级。这意味着，如果单步和多步方法都产生了正确结果而非检索方法失败，我们将为其对应查询分配标签‘`**B**`’，如图5所示。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*2Oyy-yF9K33Yrm0n.png)

* 如果所有三种方法都未能生成正确答案，则表明某些问题仍未被标记。在这种情况下，直接从公共数据集中进行分配。具体来说，我们为单跳数据集中的查询分配‘`**B**`’，为多跳数据集中的查询分配‘`**C**`’。

**训练与推理**

训练方法涉及使用交叉熵损失基于这些自动收集的查询-复杂度对来训练分类器。

然后，在推理过程中，我们可以通过将查询转发到分类器来确定查询的复杂度，即{‘`**A**`’, ‘`**B**`’, ‘`**C**`’}之一：`**o = Classifier(q)**`。

**分类器大小的选择**

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*IoBk3_J2NZRgZRef.png)

如图6所示，不同大小的分类器之间没有显著的性能差异。即使是较小的模型也不会影响性能，从而有助于资源效率。

接下来，我们将介绍一种查询细化方法：RQ-RAG。

# RQ-RAG：学习优化查询以增强生成式检索

针对上述挑战，RQ-RAG提出了三项改进措施，如图7所示。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*RArRxi23B_bOroWB.png)

* 对于简单的询问，如日常问候，引入上下文实际上可能会降低回复质量。大型语言模型应直接回应，避免添加不必要的上下文，以防产生低质量的回复。换言之，模型应学会按需回应，如图7左上角所示。
* 对于复杂的查询，将其分解为更简单、可回答的子查询。然后为每个子查询检索相应信息，从而形成对原始复杂查询的全面回应，如图7右上角所示。
* 对于具有多种潜在回应的模糊查询，仅使用初始查询语句进行检索是不够的。大型语言模型必须学会澄清查询、识别用户意图，并据此制定具体搜索策略。这种方法有助于检索全面且准确的信息来回答问题，如图7底部所示。

从RQ-RAG的核心思想可以看出，该算法的关键在于对查询进行分类和优化。

RQ-RAG的方法涉及以端到端方式训练Llama2 7B模型。这使得模型能够通过重写、分解和澄清模糊之处来动态增强搜索查询。

由于[RQ-RAG的代码](https://github.com/chanchimin/RQ-RAG)目前[正在重构](https://github.com/chanchimin/RQ-RAG/tree/96b4ec981d4a4399e8402da1b75e16f7812aedfe)，部分功能尚未运行。因此，此处不提供演示。

## 数据集构建

鉴于其端到端特性，聚焦于数据构建策略至关重要。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*BdYyIDqJs-c7kKh4.png)

[数据集的构建](https://github.com/chanchimin/RQ-RAG/blob/96b4ec981d4a4399e8402da1b75e16f7812aedfe/data_curation/main_multiturn_answer_generate.py)主要包含以下步骤：

1. 收集语料库，如图9所示，涵盖多轮对话、需分解查询及需消歧查询等多种场景，以此创建任务池。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*KKM5HK0tzvCsWqgm.png)

2. 任务池中的任务分为多轮对话、分解和消歧三类。例如，多轮对话数据集中的样本归入多轮对话类别。

3. 首先，利用ChatGPT对各类查询进行细化，随后基于这些细化查询从外部数据源检索信息。通常，DuckDuckGo为主要来源，检索过程视为黑箱操作。

4. 接着，提示ChatGPT根据细化查询及其对应上下文生成修订响应。通过重复此过程，累计约达4万实例。

图10、11和12展示了与ChatGPT交互的提示模板，蓝色文本作为特定输入的占位符。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*AFTYb4_27UB3t0SK.png)

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*nv9L-cm9B8GsOge6.png)

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*F3ziL_Lgg98WHjpc.png)

完成上述流程后，可获得图13右侧所示的训练样本。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*fJTFSVsd5KIVU1Eh.png)

每个样本为含特殊标记的操作序列，其中：

* ‘`**Xorigin**`’ 和 ‘`**Yorigin**`’ 表示原始数据集中的输入-输出对。
* ‘`**Type**`’ 指优化动作：重写、分解或消除歧义。
* ‘`**i**`’ 表示迭代轮次。
* ‘`**SPECIALtype**`’ 代表优化类型。
* ‘`**Qi, type**`’ 表示根据第i轮特定特殊标记优化的查询。
* ‘`**[Di1, Di2, . . . , Dik]**`’ 表示第i轮检索的前k篇文档。
* ‘`**Ynew**`’ 表示最终迭代步骤中生成的新答案。

## 训练

获取训练数据集后，我们可以用它以标准的自回归方式[训练一个LLM](https://github.com/chanchimin/RQ-RAG/blob/96b4ec981d4a4399e8402da1b75e16f7812aedfe/retrieval_lm/finetune.py)。训练目标如图14所示。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*BYyIcP7KJzOSGIU8.png)

简而言之，训练的目标是调整模型参数，使得在第i步，给定原始输入`**x**`、增强查询`**qi**`和检索到的文档`**di**`时，模型`**M**`应为响应`**y**`生成最高概率。

## 答案选择

在每次迭代过程中，模型会解码出多样化的搜索查询，以满足特定的需求：重写、分解或消除歧义。这些查询进而获取不同的上下文，导致扩展路径的多样化。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*aEPwcj74JDH_Ky6u.png)

如图15所示，RQ-RAG采用了[树解码策略并使用三种选择方法](https://github.com/chanchimin/RQ-RAG/blob/96b4ec981d4a4399e8402da1b75e16f7812aedfe/retrieval_lm/output/sample_from_tree.py)：基于PPL的选择、基于置信度的选择和基于集成模型的选择。

在基于PPL的选择中，会从总输出中选择困惑度（PPL）最低的答案。而基于置信度的选择则选取所有置信度最高的答案。最后，基于集成模型的选择会根据累积置信度得分选择最终结果。

# 洞察与思考

## 与自适应RAG和CRAG的比较

与自适应RAG和RQ-RAG不同，[自适应RAG](https://readmedium.com/advanced-rag-08-self-rag-c0c5b5952e0e)和[CRAG](https://ai.gopubby.com/advanced-rag-10-corrective-retrieval-augmented-generation-crag-3f5a140796f9)在检索前并不增强原始查询。相反，它们的重心在于决定是否执行检索以及如何优化检索后的操作。值得一提的是，CRAG会重写查询以进行网页搜索，从而提高检索信息的品质。

RQ-RAG和自适应RAG均通过训练一个较小的LLM来替代原有的LLM。而自适应RAG和CRAG则不替换原有LLM，而是在其基础上增加查询分类层或评估层。

作为新晋技术，根据各自论文中的实验报告，自适应RAG和RQ-RAG均声称在性能上超越了自适应RAG。

从生成过程的角度来看，自适应RAG、CRAG和自适应RAG更为简洁，因为它们不采用树解码方式。

## 关于工程实施

在查询被转化为多轮对话的场景中，使用更长的提示数据与LLM可能会导致延迟。基于我目前的理解，并行化可能是一个可行的解决方案。

此外，Adaptive-RAG和RQ-RAG都将查询分类。但这些分类是否最优？它们是否适用于特定的工业场景？其他分类方法是否能产生更好的结果？进行对比实验是必要的，以证明这些观点。

## 小模型也能表现出色

RQ-RAG 的过程展示了一个 7B 模型通过精心构建数据集和生成过程，能够取得令人瞩目的成果。

追求过大的模型规模并不一定能带来成本效益的提升。对于资源有限的团队而言，深入研究数据集和算法或许是更为合适的策略。

# 结论

本文介绍了两种高级解决方案：查询分类和查询细化，并辅以代码解释。同时，也分享了我的见解和思考。

如果您对RAG技术感兴趣，欢迎查阅我的其他文章。

最新的AI相关内容可在[我的通讯](https://florianjune.substack.com/)中找到。

最后，如有任何错误或遗漏，或您有任何想法希望分享，请随时在评论区讨论。
