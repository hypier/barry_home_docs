
---
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*OLG8kibSTT8IUTUt-GZBOw.png
date: '2024-02-15 20:04:20'
tags:
  - PDF解析
  - 科学论文
  - 公式提取
title: 揭示PDF解析如何从科学PDF论文中提取公式

---


> 本文是[高级RAG 02：揭示PDF解析](https://readmedium.com/advanced-rag-02-unveiling-pdf-parsing-b84ae866344e)的补充。

**从科学论文中提取公式一直是一个具有挑战性的任务。**

有一些工具可以识别科学论文中的公式，例如：

* [Nougat](https://arxiv.org/pdf/2308.13418.pdf)：用于学术文档的神经光学理解，是一种端到端可训练的编码器-解码器变换器模型，用于将文档页面转换为标记。
* [grobid](https://github.com/kermitt2/grobid)：图2表明其性能不如Nougat。
* [LaTeX-OCR](https://github.com/lukas-blecher/LaTeX-OCR/)：图2表明其性能不如Nougat。
* [Donut](https://arxiv.org/pdf/2111.15664.pdf)**:** Nougat基于其模型架构。
* [Mathpix Snip](https://mathpix.com/)：一款付费工具。

在本文中，我们使用[开源Nougat框架](https://github.com/facebookresearch/nougat)，架构如图1所示：



对于科学论文，公式识别的准确性很高，如图2所示：

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*nSaFINNlZT879d7IxejC6g.png)

作为演示，我们使用论文“[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)”第5页的一些公式，如图3所示。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*Y4TMxTDYyHQUeW5J2AgFsA.png)

执行命令`**nougat YOUR_PDF_PATH -o YOUR_OUTPUT_DIR_PATH**`后获得的结果如下：


```python
...
...
...

Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.

\[\mathrm{MultiHead}(Q,K,V) =\mathrm{Concat}(\mathrm{head}_{1},...,\mathrm{head}_{\mathrm{h}})W^ {O}\] \[\text{where }\mathrm{head}_{\mathrm{i}} =\mathrm{Attention}(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V})\]

Where the projections are parameter matrices \(W_{i}^{Q}\in\mathbb{R}^{d_{\text{model}}\times d_{k}}\), \(W_{i}^{K}\in\mathbb{R}^{d_{\text{model}}\times d_{k}}\), \(W_{i}^{V}\in\mathbb{R}^{d_{\text{model}}\times d_{v}}\) and \(W^{O}\in\mathbb{R}^{hd_{v}\times d_{\text{model}}}\).

In this work we employ \(h=8\) parallel attention layers, or heads. For each of these we use \(d_{k}=d_{v}=d_{\text{model}}/h=64\). Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.

...
...
...

### 位置-wise前馈网络

除了注意力子层外，我们的编码器和解码器中的每一层都包含一个全连接前馈网络，该网络应用于每个位置，并且相同。这由两个线性变换组成，中间有一个ReLU激活。

\[\mathrm{FFN}(x)=\max(0,xW_{1}+b_{1})W_{2}+b_{2} \tag{2}\]

虽然不同位置的线性变换相同，但它们在层与层之间使用不同的参数。另一种描述方式是将其视为两个卷积，卷积核大小为1。输入和输出的维度为\(d_{\text{model}}=512\)，而内层的维度为\(d_{ff}=2048\)。

...
...
...
```
解析结果是一个mmd格式文件。[在vscode中下载相应的插件](https://mathpix.com/docs/mathpix-markdown/how-to-mmd-vscode)。渲染后的结果如图4和5所示。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*wNZFcVnwlsx3taEIkRBYqQ.png)

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mTBytO0mk-e3FDkmI8Q87Q.png)

可以观察到，公式确实被准确解析。然而，在章节标题“3.3 位置-wise前馈网络”中，“3.3”缺失。

值得一提的是，Nougat在“[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)”论文中的表1上表现良好，这是因为表1包含公式。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*GexXBDEIdpdJ0wVXbRkEFw.png)

感兴趣的读者可以尝试一下。

# 结论

总体而言，Nougat 是一个出色的公式提取工具。

然而，作为一个端到端的工具（它不需要任何与 OCR 相关的输入或模块，网络隐式地识别文本），它缺乏中间结果，并且似乎定制选项有限。

此外，Nougat 使用自回归前向传播进行文本生成，这导致相对较慢的生成速度，并增加了产生幻觉和重复的可能性。

最后，如果您有任何问题，请在评论区中指出。
