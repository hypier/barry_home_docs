
---
categories: 人工智能
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*S6Cl3LE3Wbwvk2TGMem32A.png
date: '2024-08-08 18:44:15'
tags:
  - RAG
  - LLM代理
  - 复杂问题解决
title: 可控代理用于复杂的RAG任务

---


[实现](https://github.com/NirDiamant/Controllable-RAG-Agent)

[讲座](https://www.youtube.com/watch?v=b4v7tjxQkvg&t=933s)

# 介绍

如今，随着大型语言模型的兴起，每个人都希望与他们的数据进行对话并提出问题。因此，检索增强生成（RAG）变得非常流行。标准的RAG管道包括数据摄取和检索（有许多技术可以优化这些步骤以适应您的特定问题和数据），然后将用户查询与检索到的信息一起输入到LLM中以生成响应。

然而，在某些情况下，我们想要询问的数据和问题并不简单。这些情况需要一个更复杂的代理，具备推理能力，通过多个步骤来解决问题。在本文中，我将展示我如何解决这个问题，以《哈利·波特》第一本书作为用例。



# 理解 RAG 和代理

我们已经讨论了一些关于 RAG 的内容，但在 LLM 领域中，代理是什么呢？

LLM 代理是先进的 AI 系统，旨在创建需要顺序推理的复杂文本。它们能够提前思考，记住过去的对话，并使用不同的工具根据所需的情况和风格调整它们的响应。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*HZgs1MYM-5FWrluD7hxV3w.jpeg)

# 语义相似性在检索中的局限性

传统的RAG系统通常依赖于语义相似性进行检索。这种方法衡量两段文本的含义彼此接近的程度，通常使用向量表示和相似性得分。虽然对于简单查询有效，但在需要多步骤推理或理解更广泛上下文的复杂任务中，它显得力不从心。语义相似性可能会检索到相关的单个片段，但在需要跨多个来源进行信息综合或逻辑推理的问题上却显得乏力。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iBWAt9I2DXg8Hip5cPnGbA.png)

# 常规代理的挑战

常规代理的问题在于我们给予它们的自主权水平与我们拥有的控制权之间的权衡。另一种选择是构建我们自己的工作流程。

使用常规代理时：- 无法控制它何时使用工具或以何种顺序使用工具。- 无法控制它从使用工具中得出的结论。- 更难追踪幻觉/使用预训练知识的情况。

使用工作流程工程时：- 定义您解决问题的具体路径。- 完全控制每一步。- 需要量身定制的解决方案，随着问题变得更加复杂，设计可能会耗时且复杂。

# 我们的使命：为复杂的RAG任务创建一个可控的代理

现在我们了解了RAG和代理，让我们开始我们的使命，创建一个可以解决复杂RAG任务并且我们可以控制的代理。

在这种情况下，我们希望拥有三种类型的向量存储：1. 基于书籍片段的常规向量存储 2. 包含章节摘要以获取更高粒度信息的向量存储 3. 包含书中引用以获取特定高分辨率信息的向量存储

**验证RAG管道的代理的简单流程工程：**

1. 该过程开始于检索与给定问题相关的上下文。 2. 然后对该上下文进行过滤，仅保留最相关的内容。 3. 使用这个精炼的上下文，代理尝试回答问题。 4. 对答案进行相关性和潜在幻觉的评估： — 如果答案相关且不是幻觉，过程成功结束。 — 如果答案被认为是幻觉但可能有用，代理将返回以检索更多上下文。 — 如果答案不相关或无用，则重写问题。 5. 重写的问题被反馈到上下文检索步骤，过程重复，直到产生满意的答案。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hRZzITFu95TU6xTbNIZFCg.jpeg)

这可能是一个不错的解决方案，但对于复杂问题来说还不够。

**示例：复杂问题解决**

让我们看一个需要推理的复杂问题的例子：“主角是如何击败反派的助手的？”

要解决这个问题，需要以下步骤：1. 确定情节中的主角。 2. 确定反派。 3. 确定反派的助手。 4. 搜索主角与反派之间的对抗或互动。 5. 推断导致主角击败助手的原因。

# 所需能力

因此，我们在解决方案中可能需要的能力包括：1. 工具 2. 推理 3. 流程 4. 控制 5. 验证 6. 停止条件 7. 评估

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*02-9YCpL905_q-UJTUnq6w.png)

# 实施组件

我们在案例中可能使用的工具应包括检索和回答。将之前的图形拆分成几个子图将作为新代理图的工具。

对于推理和流程，我们可能需要以下组件：

1. 规划器：给定一个问题，构建我们需要执行的步骤计划，以达到最终解决方案。
2. 一个将计划步骤拆分为检索或回答任务的组件。
3. 一个任务处理组件，选择在每个步骤中使用哪个工具。
4. 一个重新规划组件，根据之前完成的步骤和我们在每个时刻收集到的当前信息在线更新计划。
5. 检索和回答工具，这两者本身也构建为小代理，按照我们希望监控它们的方式（清理检索信息，验证其是否基于上下文，幻觉检查）。
6. （可选）问题匿名化组件：生成一个没有任何基于先前知识的偏见的一般计划。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*FdaZ6jK6mUpDC7n7Xsd6uQ.png)

# 停止条件

如何确定过程何时完成？有几种选择：- 在每次重新规划访问时检查是否可以根据迄今为止汇总的信息回答问题。- 持续收集相关数据，直到过程达到饱和（新有趣信息的数量低于某个阈值）。- 通过预定义的迭代次数限制图的递归。

# 完整的代理逻辑

可控代理用于复杂的RAG任务，遵循一个复杂的多步骤过程：

1. 该过程首先通过匿名化输入问题来减少潜在的偏见。

2. 然后，规划者创建一个一般计划来回答匿名化的问题。

3. 该计划被去匿名化，以重新引入特定的上下文。

4. 该计划被分解为检索或回答任务。

5. 任务处理器根据每个任务的性质决定使用哪个工具：检索书籍片段 — 检索书籍引用 — 检索摘要 — 直接回答问题

6. 对于检索任务，系统获取相关信息，然后过滤以仅保留最相关的内容，确保其基于原始上下文。

7. 如果选择的工具是回答，系统尝试提供答案。

8. 答案会检查是否存在幻觉以及是否基于提供的上下文。

9. 如果问题尚无法回答，或者答案不令人满意，系统进入重新规划阶段。

10. 重新规划步骤评估问题是否可以用当前信息回答，或者是否需要更多检索。

11. 如果问题可以回答，系统将继续获取最终答案。

12. 最终答案再次检查幻觉，并确保其基于上下文。

13. 如果最终答案通过这些检查，过程成功结束。

这种迭代和多方面的方法使代理能够通过分解复杂查询、检索相关信息并不断完善其方法，直到产生令人满意且有充分依据的答案。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iiibLDqVF2IKx0ySkzDdYw.jpeg)

# 评估

由于这是一个 RAG 任务，我们可以像其他 RAG 任务一样进行评估。我选择基于 QA 银行的自定义基准进行评估，使用以下指标：

- 答案正确性：衡量生成的答案是否在事实上正确。- 可信度：衡量生成的答案与检索到的信息的支持程度。- 答案相关性：衡量生成的答案与问题的相关程度。- 答案相似性：衡量生成的答案与真实答案之间的语义相似性。

# 结论

通过实施这个可控代理来处理复杂的 RAG 任务，我们可以在自主性和控制之间保持平衡。这种方法允许对复杂查询提供更准确和可追溯的响应，为与大量文本（如小说或技术文档）的交互和提取见解开辟了新的可能性。

# 演示

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*MjQ8qwDcbBq3vFKnSVty5Q.gif)

如果您觉得这篇文章信息丰富且有价值，我将非常感谢您的支持：

* 在 Medium 上为它点赞几次 👏，帮助其他人发现这篇内容（您知道您可以点赞多达 50 次吗？）。您的点赞将帮助将知识传播给更多读者。
* 与您的 AI 爱好者和专业人士网络分享。
* 在 [LinkedIn](https://www.linkedin.com/in/nir-diamant-759323134/) 上与我联系。

您的参与有助于在快速发展的 AI 和语言模型领域促进知识共享的社区。
