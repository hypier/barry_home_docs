
---
categories: 人工智能
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*uQsDSXLZwcboUa6AAImazw.jpeg
date: '2024-08-23 22:33:52'
tags:
  - 多智能体系统
  - 大型语言模型
  - 人工智能优化
title: 如何利用多智能体系统提高单个 LLM 的性能

---

## 探索多AI代理系统有效性的关键因素

我们借用来自各个领域的概念和工具，为他人创造创新解决方案。几年前，我使用NLP概念和工具构建了一个在微控制器上运行的低计算量手势识别引擎。这种方法非常成功，获得了几项美国专利，并成功推出了一款发往全球10万多客户的可穿戴产品。对我来说，在LLM的背景下使用多代理系统（MAS）是这个理念的另一个例子。

AI社区借用并混合了这个概念与LLM，以解决更复杂的任务或问题。MAS在AI研究领域已经存在很长时间。我们在**群体机器人**和**生物启发优化**技术中使用了这个概念。理解MAS与LLM的结合为何优于单一LLM对我们所有人都很重要。如果是这样，我们可以迈出下一步，进一步推动性能。

**多代理系统**是相互作用的元素或代理的组合。每个代理都有自己的目标和工具。它们可以使用许多工具，例如解析器、收集器或计算器。这些代理可以线性序列或更复杂的结构（例如互联网络）进行交互。我们出于许多原因使用多代理系统架构。它可以解决单一代理无法解决的问题。它具有更**模块化**和**透明**的架构，从而导致更高效的解决方案。

之前介绍了几种方法来增强单一LLM的性能：[**思维链**](https://arxiv.org/pdf/2201.11903)、[**自我一致性**](https://arxiv.org/pdf/2203.11171)**、** [**自我反思**](https://arxiv.org/pdf/2310.03714)和[**护栏**](https://arxiv.org/pdf/2305.14292)。使用多AI代理是改善最终结果的另一种有效方法，这是我们在本文中要探讨的。在这里，我想强调我们在多代理系统中使用的几个概念，这些概念带来了良好的结果：(1) **分布式智能，** (2) **结构化提示，** 和 (3) **增强上下文。** 正如我上面所说，通过利用文献中的想法，我们可以继续改善多AI代理系统的结果。

下面这篇由伯克利AI研究中心撰写的文章让我受益匪浅。你也应该阅读它。

# 1— 分布式智能

长期以来，工程师们一直专注于设计复杂的数学模型（主要是微分方程）来描述物理、生物和经济系统。然而，他们最终发现，设计单一模型并不足够有效和准确。**他们得出结论，一个相互作用的简单模型网络往往优于单一复杂模型。** 这正是LLM领域所发生的情况。一个拥有100B+参数的巨大LLM也面临着无法在单一模型架构中解决的问题 [[Read More](https://uwaterloo.ca/complexity-innovation/about/what-are-complex-systems)]。

群体智能是一个很好的例子，说明相互作用的简单模型网络如何有效地工作。例如，基于蚂蚁行为的[蚁群优化技术](https://en.wikipedia.org/wiki/Ant_colony_optimization_algorithms)是通过使用信息素轨迹来寻找有效路径而开发的。在这个例子中，蚂蚁是代理，而信息素轨迹是通信架构。蚁群行为的集体结果，建立在简单代理任务和广泛互动的基础上，远远超出了单个代理的能力。这正是我们在多AI代理系统中所看到的情况。[[YouTube](https://www.youtube.com/watch?v=xWSkbsIRNMg)]

在多AI代理系统中，我们拥有一个代理网络，每个代理都由LLM和一组工具驱动。每个代理都针对特定任务进行了调整，例如信息检索或摘要生成。代理之间通过传递数据进行通信。网络的模块化架构允许您单独改进代理。您可以与其他团队合作解决高级问题，因为一个代理的设计不会干扰其他代理。例如，如果已经存在高性能代理，为什么还必须构建自己的摘要生成代理呢？

## ⏰ TLDR;


> 一个具有100B+参数的单一巨大LLM也存在无法在单模型架构中解决的问题。解决方案是使用分布式智能概念与多模型架构，这可以在多智能体系统中实现。

# 2— 结构化提示

这可能显而易见，但值得一提。人工智能行业长期以来受益于结构化数据。许多当前的传统人工智能模型在处理结构化数据时表现更好。那么大型语言模型（LLMs）为什么不呢？

一个复杂的提示，包括上下文和指令，可能会让人类和LLMs感到困惑。为了在复杂提示中增加清晰度，我们经常使用标准结构的模板，文献已证明这是一种有效的方法。这个想法促使人工智能社区开发了诸如 [Outlines](https://outlines-dev.github.io/outlines/welcome/) 和 [LMQL](https://lmql.ai/) 的工具，这些库用于编写强大且模块化的提示。

使用结构化提示可以通过增强清晰度和重点来改善LLM的结果。尽管结构化提示需要更多的初始努力，但它显著提高了模型结果的质量、一致性和效率。在多人工智能代理系统（例如 [crewAI](https://www.crewai.com/) 的实现）中，我们使用结构化接口或提示来定义 `Tool`、`Task` 和 `Agent`（MAS的三个基础）。例如，我们为每个代理清晰明确地定义 `role`、`goal` 和 `context`（在crewAI中称为 `backstory`）。

您可以在下面找到使用结构化提示在crewAI中创建代理的示例。 [[阅读更多](https://docs.crewai.com/core-concepts/Agents/#creating-an-agent:~:text=%23%20Example%3A%20Creating%20an%20agent%20with%20all%20attributes)]


```python
custom_agent = Agent(
 role = "Text",
 goal = "Text",
 backstory = "Text",
 allow_delegation = Boolean,
 verbose = Boolean
)
```

## ⏰ TLDR;

> 一个复杂的单一提示，包括上下文和指令，可能会使人类和大型语言模型感到困惑。为了提高清晰度和专注度，我们必须将复杂的提示分解为结构化的简单提示，就像我们在MAS实现中所做的那样。

# 3— 增强上下文

一个常见的挑战是，LLM（大语言模型）是在历史数据上进行训练的，这限制了它们获取最新信息的能力。AI社区提出了检索增强生成（RAG）技术，以提取最相关和真实的数据，从而增强LLM的上下文。提示中的相关和真实上下文帮助我们提高问答用例的性能。一个使用RAG的小型LLM（如Llama 8B）可能比一个没有RAG的大型LLM（Llama 405B）表现更好。

RAG本身就是一种强大的技术，可以提高单个LLM的性能。在RAG中，我们利用了先进的技术，如**文本嵌入**、**重排序**和**格式感知分块**，以提取给定查询的最相关上下文。我们还在多AI代理系统中使用RAG代理。但是，还有其他方法可以增强LLM的上下文吗？

答案是肯定的。在多AI代理系统中，我们可以超越使用RAG代理来增强上下文。由于多AI代理系统中的代理彼此之间进行通信，传递的数据必须存储在内存中并在需要时使用。这种内存使代理在执行过程中能够相互分享知识。它还帮助保留之前运行的数据，并在最新的运行中使用。以下是使用[crewAI](https://www.crewai.com/)创建带有内存的MAS的示例。

```python
MAS = Crew(
 agents = [agent_1, agent_2, agent_3],
 tasks = [task_1, task_2, task_3],
 verbose = 2,
 memory = True 
)
```
在多AI代理系统中，有三种类型的内存：短期、长期和实体。这些内存类型的解释超出了本文的范围；您可以在[这里](https://docs.crewai.com/core-concepts/Memory/)阅读更多内容。

## ⏰ TLDR;

> RAG 不是增强 LLM 上下文的唯一解决方案。在多 AI 代理系统中，我们有一个记忆的概念，它跟踪每一步和每次运行中生成的数据，以便在后续过程中使用。

# 最后的话

我们有多种方法来提高LLMs的性能，例如思维链、自我一致性、自我反思和保护措施。另一种有效的方法是采用多智能体系统来增强LLM在生产中的性能。多智能体系统是提高单个LLM性能的另一种方法。多AI代理系统的性能优于单一AI代理，主要得益于**分布式智能**、**结构化提示**和**增强上下文**。

