
---
categories: 人工智能
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*jiibGq2JiFv9TANsh5cn6Q.png
date: '2024-08-15 16:09:05'
tags:
  - AI
  - LLM
  - PDF处理
title: 实验 1与 PDF 聊天使用 Langchain 和 Streamlit

---


*将 AI 引入我们生活的第一步是与之互动*

> **与 PDF 聊天** 是系列文章 [**“与一切聊天”**](https://github.com/S0NM/chat-with-everything/) 中的第一篇，面向那些正在学习 LLM 应用的朋友们。该系列专注于与 LLM 互动的技术，并在使用流行技术栈如 Streamlit 和 Langchain 的简单应用中实现它们。

> *您可以在这里找到“与一切聊天”系列： [我的 GitHub](https://github.com/S0NM/chat-with-everything)*

**难度等级：初学者** 🎖️

# 1. 背后的故事

## 与PDF文件的工作有多重要？

PDF是一种标准文档格式，广泛应用于日常工作中，包括日常报告、销售文件、汇总研究文档、发票信息和合同。可以说，PDF是**“包含黄金数据的知识矿”**



**实际上：** 想象一下，您是一名研究人员，正在处理包含宝贵信息的数千页PDF文档。在这堆文档中搜索特定信息是一项巨大的挑战且耗时。这时我们就需要大型语言模型（LLMs）的支持。

# 2. 让我们从一个简单的聊天应用程序开始

首先，让我们看看我们将通过这个项目实现什么：

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*7cmVyy-Br-qzseGsnhcPxA.gif)

# 3. 工作原理

我不会逐步讲解实现过程，因为你可以在这里找到：[Github 链接](https://github.com/S0NM/chat-with-everything/tree/main/chat-with-pdf)

**应用程序的工作原理在以下图片中描述：**

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*vryZbthoMMriUIrSrLLKfg.png)

两个最重要的步骤：

**1) 从任何数据源加载完整内容（这是一个 PDF）：**

为此，langchain 支持许多不同的“文档加载器”。在这里，我使用 PyPDFLoader 从 PDF 中加载内容：


```python
loader = PyPDFLoader(temp_file)  
pages = loader.load()

# Get the full content of the PDF file  
content = ""  
for page in pages:  
    content = content + "\n\n" + page.page_content  
st.session_state.content = content
```
**2) 与任何 LLM 一起工作：** 使用模板提示创建一个链。在模板提示中，两个变量 {content} 和 {question} 将在后面传递。


```python
prompt = ChatPromptTemplate.from_messages(  
    [("system", "You are a very helpful assistant"),  
     ("user",  
      "Based on my Pdf content:{content}. Please answer my question: {question}. Please use the language that I used in the question")]  
)  
llm = ChatOpenAI(api_key=OPENAI_API_KEY)  
output_parser = StrOutputParser()

# The beauty of langchain is this simple line of code  
chain = prompt | llm | output_parser
```
与 LLM 的问答过程通过代码调用


```python
response = chain.invoke({"content": st.session_state.content, "question": question})
```

# 4. 深入挖掘

如果你想挑战自己，这里有一些想法供你参考：

## 🎖️🎖️ 中级水平

* **寻找合适的模型：** 尝试不同的 LLM 模型，以找到最适合您问题的模型。
* **输入文本处理：** 为了获得最佳结果，输入文本的质量至关重要。专注于对输入文本进行预处理，例如清理、去除冗余信息或重新排列输入数据。
* **应用文本分割以处理大内容并优化处理成本：** 研究如何将大文档拆分成较小的块，以将相关块发送给 LLM 模型的技术（例如，GPT-3.5-turbo 的限制为 16,385 个标记）。GPT-4-turbo 和 GPT-4o 的限制为 128,000 个标记。

## 🎖️🎖️🎖️ 高级水平

* **高级状态管理：** 管理更复杂的对话状态，保持跨多个请求的上下文，并改善个人体验
* **处理非文本元素：** 研究在PDF中识别和处理图像、图表和表格，使用额外工具。
* **性能优化：** 在实时应用中优化向LLM模型发送请求的成本和延迟。
* **模型定制：** 使用特定领域的数据对模型进行微调，以提高专业应用的性能。

# 在你离开之前！🤟

如果你觉得这篇文章对你有帮助并希望表示支持，**为我的文章鼓掌 10 次** 👏，这将真正激励我并将这篇文章推荐给更多人。
