
---
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*iNtnt7GcDC5j2FqSD1zk-g.png
date: '2024-06-06 21:37:06'
tags:
  - 人工智能
  - 信息检索
  - 知识图谱
title: 从RAG到GraphRAG利用知识图谱革新信息检索

---


在人工智能领域，追求更精确和上下文相关的信息检索技术已取得显著进展。其中一项进化是从检索增强生成（Retrieval-Augmented Generation，简称RAG）到GraphRAG的转变，这一概念在近期[微软博客文章](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)中有详细阐述。让我们探讨RAG是什么，它的优势，以及为何需要向GraphRAG过渡。



**什么是RAG？**

检索增强生成（RAG）是一种自然语言查询方法，旨在通过外部知识增强大型语言模型（LLM）的能力。其工作原理如下：

1. **数据收集：** 从数据库、网站、文件等多种来源收集相关文档或信息。
2. **数据分块：** 将收集到的数据分割成更小、更易于处理的数据块。
3. **文档嵌入：** 将每个数据块转换为表示其语义意义的向量（嵌入）。
4. **查询嵌入：** 将用户的查询转换为向量格式，以捕捉其语义本质。
5. **相似度匹配：** 比较查询向量与文档向量，找出最相关的数据块。
6. **响应生成：** 利用语言模型根据检索到的数据块生成连贯且上下文准确的响应。

通过这些步骤，RAG有效地结合了检索和生成技术，提高了响应的准确性和相关性，使其成为多种应用的强大工具。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mZJPOHJ-s_do-A6m7BHijg.png)

# GraphRAG的必要性

尽管RAG显著提升了LLM的性能，但在处理复杂查询和大型数据集方面仍有改进空间。这促使了GraphRAG的开发，它在RAG的基础上构建，但引入了更复杂的索引和检索方法。

# GraphRAG 简介：

GraphRAG 在 RAG 概念的基础上更进一步，引入了一个两步流程，该流程利用从大型语言模型（LLMs）中提取的知识图谱。以下是 GraphRAG 的工作原理：

## 第一步：基于知识图谱的索引

GraphRAG 的第一步是从私有数据中创建由 LLM 衍生的知识图谱。这些知识图谱作为 LLM 的一种记忆表示形式，捕捉数据中的语义关系。这种丰富的表示形式使得后续步骤中的信息检索更加有效。

## 第二步：LLM 编排

在第二步中，利用预构建的索引（知识图谱）来编排大型语言模型（LLMs）。这种编排机制通过利用知识图谱来增强检索增强生成（RAG）操作，从而实现更准确和上下文相关的结果。

# GraphRAG的关键差异化优势

GraphRAG提供了多项优势，使其与传统的RAG方法区别开来：

1. 提升搜索相关性：通过全面理解整个数据集的语义，GraphRAG提高了搜索结果的相关性。
2. 支持新型应用场景：它支持需要大上下文窗口的复杂场景，如整体数据集分析、趋势总结和数据聚合。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*e0ZDPWMvSoPjVQrV6iwDmg.png)

# GraphRAG 的工作原理

要理解 GraphRAG，关键在于将其与基线 RAG 进行比较。在基线 RAG 中，私有数据集被分割成嵌入向量并存储在向量数据库中，通过执行最近邻搜索来扩充上下文窗口。

GraphRAG 沿用了这一流程，但增加了额外的推理层。以下是逐步分解：

1. 文本分块与推理：使用相同的文本块，但大型语言模型（LLM）对数据集中的每个句子进行推理操作。
2. 实体与关系抽取：命名实体识别（NER）识别文本中的实体，但 GraphRAG 更进一步，确定实体间的关系及其关系的强度。
3. 知识图谱构建：抽取的关系形成一个知识图谱，包含节点（实体）和边（关系）。

## 示例：

* 句子：“PO 负责人 Sylvia Mar 与 Save Our Wildlands 创始人 Luo Jack 同台亮相。”
* GraphRAG 识别出 Sylvia Mar 与 PO 的强关联（她是负责人）以及与 Save Our Wildlands 的弱关联（虽同台但非负责人）。

这种更深层次的理解使得 GraphRAG 能够创建加权图，超越传统 NER 的共现网络，实现更丰富的语义分析。

## RAG系统对比：

* 基线RAG：在处理特定查询时表现不佳，往往无法提供全面的答案。
* 改进型RAG：通过调优和提示工程性能有所提升，但在复杂查询中仍缺乏深度。
* GraphRAG：通过利用知识图谱提供详细且准确的回答，在丰富上下文和精确信息检索方面表现出色。

# 构建与利用知识图谱

知识图谱一旦创建，便可实现高级功能：

1. 图机器学习：可在图谱上进行语义聚合和层次聚类，生成带标签的结构，实现细粒度筛选和查询。
2. 多样的终端应用场景：知识图谱可应用于多种场景，包括数据集问题生成、摘要提取及问答系统等。

# 代码实现：

让我们逐步了解 GraphRAG 应用场景，该场景利用了包含《儿童保育提供者疾病手册》信息的医疗文档。该手册提供了关于在儿童保育环境中预防、管理和报告传染病疾病的全面细节。我们还将使用一个基本的 RAG 系统来比较每个系统的响应。

**下载 PDF — [链接](https://bluetick-website-images.s3.ap-south-1.amazonaws.com/Medical_Records.pdf)**

**Collab 链接: [Graph\_rag\_code](https://colab.research.google.com/drive/17Nxr_eNACiLBZnguCMceZNL-wLkTfZdE?usp=sharing)**


```python
pip install llama-index
pip install llama-index-llms-openai
pip install langchain

```
**导入库：**


```python
import os
from llama_index.core import (KnowledgeGraphIndex,ServiceContext,SimpleDirectoryReader)
from llama_index.core.indices.vector_store.base import VectorStoreIndex
from llama_index.core import Settings
from llama_index.llms.openai import OpenAI
from llama_index.core.graph_stores import SimpleGraphStore
from llama_index.core import StorageContext
```

## 预处理数据与定义LLM：


```python
documents = SimpleDirectoryReader(input_files=["disease-handbook-complete.pdf"]).load_data()
```

```python
llm = OpenAI(temperature=0, model="gpt-4-turbo",api_key=API_KEY)
Settings.llm = llm
Settings.chunk_size = 512
service_context = ServiceContext.from_defaults(llm=llm, chunk_size=512)

```

## 构建知识图谱

知识图谱是通过使用LLM创建的。这一过程借助了LlamaIndex中的KnowledgeGraphIndex，该索引利用LLM提取实体及其关系，然后将它们存储在SimpleGraphStore()中。

```python
graph_store = SimpleGraphStore()
storage_context = StorageContext.from_defaults(graph_store=graph_store)

kg_index = KnowledgeGraphIndex.from_documents(
    documents,
    max_triplets_per_chunk=2,
    storage_context=storage_context,
    service_context=service_context)
```
![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*w8pWyDaMjOQe_mNSXGXn7Q.png)

## 设置用于检索增强生成（RAG）的 VectorStoreIndex：

为了与基于向量数据库的RAG对比，我们还将建立一个VectorStoreIndex。在其设置过程中，相同的数据源将被分割成块，并创建它们的嵌入表示。在RAG查询时，将使用查询的嵌入表示通过向量搜索找到最相关的top-k嵌入。

```python
vector_index = VectorStoreIndex.from_documents(
    documents,
    service_context=service_context
)
```

## 保存和加载Llama索引到磁盘

知识图谱索引（KnowledgeGraphIndex）和向量存储索引（VectorStoreIndex）一旦创建，其内存中的上下文可以保存到磁盘，以便随时重新加载和重用。

```python
dir_vector= folder_path_vector
dir_graph= folder_path_graph
kg_index.storage_context.persist(persist_dir=dir_graph)
vector_index.storage_context.persist(persist_dir=dir_vector)
```

## 从磁盘恢复索引

这使我们能够按如下方式从磁盘恢复索引：

```python
from llama_index.core import load_index_from_storage

storage_context = StorageContext.from_defaults(persist_dir=dir_graph, graph_store=graph_store)
kg_index = load_index_from_storage(
    storage_context=storage_context,
    service_context=service_context,
    max_triplets_per_chunk=10,
    include_embeddings=True,
)

storage_context_vector = StorageContext.from_defaults(persist_dir=dir_vector)
vector_index = load_index_from_storage(
    service_context=service_context,
    storage_context=storage_context_vector)
```

## RAG查询引擎设置：

Vector RAG 找到与查询语义相关的最相关的 top-k 文档块，作为合成答案的上下文，而 GraphRAG 则使用与任务或问题中的实体相关的子图作为上下文。

```python
kg_rag_query_engine = kg_index.as_query_engine(
    include_text=False,
    retriever_mode="keyword",
    response_mode="tree_summarize",
)
vector_rag_query_engine = vector_index.as_query_engine()
```

## RAG 引擎查询

让我们尝试向每个引擎提出多个问题，并分析它们的性能。目前，我们先尝试以下问题：

“**在托儿所环境中，应采取哪些措施来预防结膜炎（红眼病）的传播？**”

## 使用GraphRAG进行查询

```python
result_graph_rag = kg_rag_query_engine.query("在托儿所环境中，应采取哪些步骤来预防结膜炎（红眼病）的传播？")

```

## 响应：

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*aHuIU4MJl37sWg98jxcScw.png)

**使用RAG进行查询**


```python
result_vector_rag = vector_rag_query_engine.query("在托儿所环境中，应采取哪些步骤来预防结膜炎（红眼病）的传播？")
```

## 回复：

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*_LXBxEoP7lLtZJAmE43ENQ.png)

## 来自两份回复的观察

为了评估GraphRAG和Vector Rag的回复，我们需要比较它们提供的预防儿童保育环境中结膜炎传播步骤的全面性、准确性和综合性。

**比较：**

**全面性：**

* GraphRAG的回复提供了更广泛的预防措施，涵盖了手卫生、避免眼部接触、不共用个人物品、清洁表面、对员工和家长进行教育、隔离有症状的儿童以及咨询医疗保健提供者。
* Vector Rag的回复主要集中在与洗涤物品、洗手和为每个孩子使用单独物品相关的卫生实践上，但没有提及其他预防措施，如教育员工和家长、隔离有症状的儿童或咨询医疗保健提供者。

**准确性：**

* 两份回复的建议都是准确的，但GraphRAG包含了Vector Rag未提及的一些重要步骤。

**综合性：**

* GraphRAG更为全面，涉及了更广泛的预防措施，以防止结膜炎的传播。
* Vector Rag相对不够全面，更侧重于特定的卫生实践，而未涉及一些更广泛的预防措施。

**问题-回复比较表**

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*SgYff07hXUQQJLeC5Bv62Q.png)

**GraphRAG**的回复更优，因为它提供了一套更全面和综合的步骤，涵盖了更广泛的预防行动，并确保了在儿童保育环境中管理结膜炎的全面方法。

# 结论

从RAG到GraphRAG的演进标志着利用大型语言模型进行信息检索和生成的重大里程碑。通过利用LLM衍生的知识图谱，GraphRAG不仅提高了搜索结果的相关性，还开启了复杂数据分析和上下文理解的新可能性。这种先进的方法使得对数据的更细致和互联的理解成为可能，为更准确和深入的AI驱动解决方案铺平了道路。随着我们继续利用GraphRAG的力量，我们正逐步接近解锁AI在转变我们与庞大数据集交互和从中获取洞察力方面的全部潜力。
