
---
categories: äººå·¥æ™ºèƒ½
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*4UKWHHJHW4u6Lemg9sJlVg.png
date: '2024-08-15 16:09:38'
tags:
  - å¤šæ™ºèƒ½ä½“
  - CrewAI
  - LLMåº”ç”¨
title: å®éªŒ 5ä¸å¤šæ™ºèƒ½ä½“èŠå¤©CrewAIChatGPT å’Œ Streamlit

---


ä¸å¤šæ™ºèƒ½ä½“èŠå¤©å°±åƒæ‚¨æƒ³è±¡çš„é‚£ä¹ˆç®€å•

> **â€œä¸å¤šæ™ºèƒ½ä½“èŠå¤©â€** æ˜¯[**â€œä¸ä¸€åˆ‡èŠå¤©â€**](https://github.com/S0NM/chat-with-everything)ç³»åˆ—ä¸­çš„ä¸€ç¯‡æ–‡ç« ã€‚æœ¬éƒ¨åˆ†å°†é‡ç‚¹ä»‹ç»å¦‚ä½•åº”ç”¨ CrewAI å¹³å°æ„å»ºå¤šæ™ºèƒ½ä½“åº”ç”¨ç¨‹åº

> å¯¹äºé‚£äº›ä¸çŸ¥é“çš„äººï¼Œ**â€œä¸ä¸€åˆ‡èŠå¤©â€**ç³»åˆ—ä¸“æ³¨äºä¸ºæ‚¨æä¾›æ„å»º LLM åº”ç”¨ç¨‹åºçš„æŠ€æœ¯çŸ¥è¯†å’ŒæŠ€å·§ã€‚æˆ‘åˆ›å»ºçš„æ‰€æœ‰åº”ç”¨ç¨‹åºéƒ½æ˜¯ä½¿ç”¨æµè¡Œæ¡†æ¶ï¼šStreamlitã€Langchain å’Œ OpenAIï¼ˆLLM æ¨¡å‹ï¼‰ã€‚

> æ‚¨å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°â€œä¸ä¸€åˆ‡èŠå¤©â€ç³»åˆ—ï¼š[æˆ‘çš„ GitHub](https://github.com/S0NM/chat-with-everything)

## éš¾åº¦ç­‰çº§ï¼šä¸­çº§ ğŸ–ğŸ–ï¸ï¸

**åŸºäºLLMçš„ä»£ç†**çš„å¿«é€Ÿå‡ºç°å’Œé‡‡ç”¨ä½¿2024å¹´æˆä¸ºäººå·¥æ™ºèƒ½æ¼”å˜çš„é‡è¦è½¬æŠ˜ç‚¹ã€‚è¿™äº›ä»£ç†æ—¨åœ¨**è‡ªä¸»å’Œåä½œåœ°æ‰§è¡Œä»»åŠ¡**ï¼Œæ”¹å˜äº†ä¼ä¸šå’Œä¸ªäººè§£å†³é—®é¢˜å’Œæé«˜ç”Ÿäº§åŠ›çš„æ–¹å¼ã€‚

éšç€è¿™äº›ä»£ç†å˜å¾—è¶Šæ¥è¶Šå¯é ï¼Œå¹¶ç»§ç»­ä¸ºæœªæ¥çš„ä¸šåŠ¡å»ºç«‹åšå®çš„åŸºç¡€å±‚ï¼Œå®ƒä»¬çš„åä½œå°†åˆ›é€ ä¸€ä¸ªå¼ºå¤§çš„å±‚æ¬¡ï¼Œå¸®åŠ©**å¼¥åˆæŠ€æœ¯ä¸ä¸šåŠ¡ä¹‹é—´çš„å·®è·**ã€‚



æˆ‘å°†åœ¨å¦ä¸€ç¯‡æ–‡ç« ä¸­æ·±å…¥æ¢è®¨è¿™ä¸ªä¸»é¢˜ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨å¦‚ä½•é€šè¿‡å°†æ¦‚å¿µåº”ç”¨äºæ„å»ºèŠå¤©åº”ç”¨ç¨‹åºæ¥å®é™…è¿ä½œã€‚

æˆ‘ä½¿ç”¨çš„æŠ€æœ¯æ ˆæ˜¯CrewAIã€Streamlitã€Langchainå’ŒGPTä½œä¸ºå·¥ä½œæ¨¡å‹ã€‚

## æˆ‘å°†åœ¨æœ¬æ–‡ä¸­æ¶µç›–çš„å†…å®¹ï¼š

1. ä»€ä¹ˆæ˜¯åŸºäºLLMçš„ä»£ç†
2. CrewAIï¼šå¤šä»£ç†å¹³å°
3. â€œä¸å¤šä»£ç†èŠå¤©â€åº”ç”¨
4. å®æ–½
5. ç»“æœä¸æœªæ¥å·¥ä½œ

**å±•ç¤ºæ¡ˆä¾‹**ï¼ˆå¯¹äºé‚£äº›æƒ³å…ˆçœ‹åˆ°ç»“æœä»¥æ¿€åŠ±è‡ªå·±çš„è¯»è€…ï¼‰

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*SaB9uiePUfBOi9mS3yJjeg.gif)

# 1. ä»€ä¹ˆæ˜¯åŸºäºLLMçš„ä»£ç†

## ä»€ä¹ˆæ˜¯ä»£ç†ï¼Ÿ

åœ¨äººå·¥æ™ºèƒ½å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿé¢†åŸŸï¼Œä»£ç†æ˜¯èƒ½å¤Ÿ**è‡ªä¸»å’Œç‹¬ç«‹åœ°æ‰§è¡Œç‰¹å®šä»»åŠ¡**çš„è½¯ä»¶å®ä½“ã€‚è¿™äº›ä»£ç†è¢«è®¾è®¡ä¸ºæ ¹æ®**é¢„å®šä¹‰çš„è§„åˆ™å’Œç›®æ ‡**è¿›è¡Œæ“ä½œï¼Œä¸ç¯å¢ƒå’Œå…¶ä»–ä»£ç†äº’åŠ¨ï¼Œä»¥é«˜æ•ˆåœ°å®Œæˆä»»åŠ¡ã€‚

## ä»£ç†çš„å…³é”®ç‰¹å¾

ä¸ºäº†å¸®åŠ©æ‚¨ç†è§£ä»£ç†çš„ç‰¹å¾ï¼Œæˆ‘åœ¨ä¸‹é¢çš„å›¾ç‰‡ä¸­è¿›è¡Œäº†è¯´æ˜ï¼š

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*AOvgJPaSFzRvCs6cQlspbQ.png)

1. **ç›®æ ‡å¯¼å‘ï¼š** æ‚¨å¿…é¡»è®°ä½çš„é‡è¦ä¸€ç‚¹æ˜¯ï¼Œæ¯ä¸ªä»£ç†éƒ½æ˜¯ä¸ºäº†å®ç°ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å®šç›®æ ‡è€Œè®¾è®¡çš„ã€‚æ¯ä¸ªä»£ç†éƒ½æœ‰ç‰¹å®šçš„ç›®æ ‡æ¥æŒ‡å¯¼å…¶è¡ŒåŠ¨å’Œå†³ç­–ã€‚ä»£ç†å¯ä»¥æ ¹æ®é‡è¦æ€§å’Œç´§æ€¥æ€§å¯¹ä»»åŠ¡è¿›è¡Œä¼˜å…ˆçº§æ’åºã€‚
2. **é€‚åº”æ€§ï¼š** ä»£ç†å…·æœ‰é€‚åº”å˜åŒ–æƒ…å†µå’Œç¯å¢ƒçš„èƒ½åŠ›ã€‚å®ƒä»¬å¯ä»¥æ ¹æ®æ¥è‡ªç¯å¢ƒçš„åé¦ˆï¼ˆä¾‹å¦‚æ–‡æœ¬ã€éŸ³é¢‘ã€è§†é¢‘ç­‰ï¼‰è°ƒæ•´å…¶è¡Œä¸ºã€‚ä»£ç†å¯ä»¥æ ¹æ®æ–°ä¿¡æ¯å’Œå˜åŒ–çš„æ¡ä»¶æ”¹å˜å…¶æ“ä½œã€‚é«˜çº§ä»£ç†è¿˜å¯ä»¥é€šè¿‡ç»éªŒå­¦ä¹ æ¥æé«˜æ€§èƒ½ã€‚
3. **äº’åŠ¨æ€§ï¼š** ä»£ç†å¯ä»¥ä¸å‘¨å›´ç¯å¢ƒå’Œå…¶ä»–ä»£ç†è¿›è¡Œäº’åŠ¨ã€‚è¿™ä½¿å®ƒä»¬èƒ½å¤Ÿåè°ƒå¹¶å…±åŒå·¥ä½œä»¥å®ç°å…±åŒç›®æ ‡ã€‚ä»£ç†ä½¿ç”¨é€šä¿¡åè®®ä¸å…¶ä»–ä»£ç†äº¤æ¢ä¿¡æ¯ï¼Œè€Œæ— éœ€äººç±»å¹²é¢„ã€‚
4. **ååº”æ€§ï¼š** ä»£ç†å¯ä»¥é€šè¿‡ä½¿ç”¨å·¥å…·ï¼ˆä¾‹å¦‚æœç´¢äº’è”ç½‘ã€æŠ“å–ç½‘ç«™ã€ä½¿ç”¨ä»£ç è§£é‡Šå™¨æ€»ç»“ä¸‹è½½å†…å®¹ç­‰ï¼‰é‡‡å–ä¸»åŠ¨æªæ–½æ¥å®Œæˆè¿™äº›ä»»åŠ¡ã€‚è¿™ä¸»è¦æ˜¯é€šè¿‡ API è°ƒç”¨å’Œå‡½æ•°è°ƒç”¨æ¥å®ç°çš„ã€‚
5. æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼Œ**ä»£ç†çš„å¤§è„‘**ä½¿ä»£ç†èƒ½å¤Ÿè‡ªä¸»å·¥ä½œï¼ŒåŸºäº LLMã€‚åŸºäºæ­¤ï¼Œä»£ç†å¯ä»¥åœ¨æ²¡æœ‰æŒç»­äººç±»å¹²é¢„çš„æƒ…å†µä¸‹åšå‡ºè‡ªå·±çš„å†³ç­–ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œæœ‰å¾ˆå¤šé€‰æ‹©ï¼Œä¾‹å¦‚ GPTã€Claudeã€Llama ç­‰ã€‚

# 2. CrewAI: å¤šæ™ºèƒ½ä½“å¹³å°

ä¸ºäº†æ¼”ç¤ºæ™ºèƒ½ä½“å¦‚ä½•ååŒå·¥ä½œï¼Œæˆ‘å°†ä½¿ç”¨CrewIï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä¼˜åŒ–æ™ºèƒ½ä½“å·¥ä½œæµç¨‹çš„å¹³å°ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šç»†èŠ‚ï¼Œè¯· [ç‚¹å‡»æ­¤é“¾æ¥](https://docs.crewai.com/)

æœ¬èŠ‚å°†å¸¦æ‚¨äº†è§£CrewAIçš„ä¸€äº›æ ¸å¿ƒæ¦‚å¿µã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ï¼š

## ç¤ºä¾‹

*ç›®æ ‡ï¼šâ€œä»ç”¨æˆ·è¾“å…¥çš„ä¸ªäººä¼ è®°ä¿¡æ¯ä¸­æå–ä¸‰ä¸ªå…³é”®ç‚¹ã€‚â€*

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*qFke6LTjOt0YZmLgL0JzsQ.png)

å®ç°ä»£ç åˆ›å»ºäº†ä¸¤ä¸ªä»£ç†ååŒå·¥ä½œï¼Œä»¥å®ç°â€œä»ç”¨æˆ·è¾“å…¥çš„ä¸ªäººä¼ è®°ä¿¡æ¯ä¸­æå–ä¸‰ä¸ªå…³é”®ç‚¹â€çš„ç›®æ ‡ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºåŸƒéš†Â·é©¬æ–¯å…‹ï¼‰ï¼š

* **æœç´¢ä»£ç†ï¼š** é…å¤‡ä½¿ç”¨â€œSerper APIâ€å·¥å…·ä»äº’è”ç½‘æœç´¢ä¿¡æ¯çš„èƒ½åŠ›
* **æ‘˜è¦ä»£ç†ï¼š** å…·å¤‡ä»æ”¶é›†åˆ°çš„ä¿¡æ¯ä¸­æ€»ç»“å’Œæå–3ä¸ªå…³é”®ç‚¹çš„èƒ½åŠ›ï¼ˆæœç´¢ä»»åŠ¡çš„è¾“å‡ºï¼‰

ç›®æ ‡è¢«åˆ†ä¸ºä¸¤ä¸ªä»»åŠ¡ï¼šæœç´¢ä»»åŠ¡å’Œæ‘˜è¦ä»»åŠ¡

## å®ç°ä»£ç 


```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import SerperDevTool
import os

# åœ¨æ­¤å¤„æ›¿æ¢ OPENAI_API_KEY & SERPER_API_KEY
# è·å– OPENAI_API_KEY çš„é“¾æ¥: https://platform.openai.com/api-keys
# è·å– SERPER_API_KEY çš„é“¾æ¥: https://serper.dev/api-key
os.environ["OPENAI_API_KEY"] = "sk-xxxxxx"
os.environ["OPENAI_MODEL_NAME"] = "gpt-3.5-turbo"
os.environ["SERPER_API_KEY"] = "799fab83yyyyy"

# å®šä¹‰ä¸€ä¸ªå·¥å…·
search_tool = SerperDevTool()

# å®šä¹‰ä¸€ä¸ªæœç´¢ä»£ç†
search_agent = Agent(
    role = "æœç´¢ä»£ç†",
    goal = "è°æ˜¯ {input}",
    backstory = """ä½ æ˜¯ä¸€ä¸ªåœ¨äº’è”ç½‘ä¸Šæœç´¢ä¼ è®°çš„ä¸“å®¶""",
    tools = [search_tool],
)

# å®šä¹‰ä¸€ä¸ªæ‘˜è¦ä»£ç†
# åˆ›å»ºä»£ç†æ—¶ï¼Œå¿…é¡»ä¸ºå…¶è®¾ç½®ç›®æ ‡å’ŒèƒŒæ™¯æ•…äº‹ã€‚
summary_agent = Agent(
    role = "ä¼ è®°æ‘˜è¦ä»£ç†",
    goal="åœ¨200å­—ä»¥å†…æ€»ç»“ä»»ä½•ä¼ è®°",
    backstory="ä½ æ˜¯ä¸€ä¸ªä»ä¼ è®°ä¸­æå–é‡è¦å’Œç®€æ˜ä¿¡æ¯çš„ä¸“å®¶",
)

# å®šä¹‰ä¸€ä¸ªæœç´¢ä»»åŠ¡ï¼Œä»¥æŸ¥æ‰¾ç”¨æˆ·è¾“å…¥çš„ {input} çš„ä¼ è®°
search_task = Task(
    description = "æœç´¢ {input} çš„ä¼ è®°",
    expected_output = "å®Œæ•´çš„ä¼ è®°",
    agent = search_agent,
    tools = [search_tool],
)

# å®šä¹‰ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ï¼Œä» search_task çš„è¾“å‡ºä¸­æå–å…³é”®ä¿¡æ¯
summary_task = Task(
    description = "ä»…æå–ä¼ è®°ä¸­çš„3ä¸ªäº®ç‚¹",
    expected_output="åŒ…å«3ä¸ªäº®ç‚¹çš„ç®€çŸ­ä¼ è®°",
    agent = summary_agent,
    context = [search_task]
)

# å®šä¹‰åŒ…å«ä»£ç†å’Œä»»åŠ¡çš„å›¢é˜Ÿ
# Process.sequential: ä»£ç†æŒ‰ç‰¹å®šé¡ºåºæ‰§è¡Œä»»åŠ¡ã€‚
my_crew = Crew(
    agents = [search_agent, summary_agent],
    tasks = [search_task, summary_task],
    process = Process.sequential,
    verbose = True
)

my_crew.kickoff(inputs={"input":"Elon musk"})
```
è¿è¡Œä¸Šè¿°ä»£ç å¹¶è·å¾—ç»“æœï¼š


```python
Here are three highlights from Elon Musk's biography:

1. Elon Musk was born in Pretoria, South Africa, to model Maye and businessman and engineer Errol Musk. He briefly attended the University of Pretoria before immigrating to Canada.

2. Musk founded X.com in 1999, which later became PayPal, SpaceX in 2002, and Tesla. He is widely known for his work with electric vehicles and space exploration.

3. Elon Musk is a creative genius known for his tenacious resilience. Despite his extraordinary success, he remains human enough to allow others to see him at his most vulnerable.
```

# 3. â€œå¤šæ™ºèƒ½ä½“èŠå¤©â€åº”ç”¨

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘å‡è®¾æ‚¨å·²ç»ç†è§£äº†æ‰€æœ‰å†…å®¹ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†è¿›å…¥ä¸€ä¸ªæ›´å¤æ‚çš„ç¤ºä¾‹ï¼š**â€œå¤šæ™ºèƒ½ä½“èŠå¤©â€**åº”ç”¨ã€‚æˆ‘ä»¬åº”ç”¨çš„é«˜å±‚è®¾è®¡å¦‚ä¸‹é¢çš„å›¾åƒæ‰€ç¤ºï¼š

*è¯¥åº”ç”¨çš„ç›®æ ‡æ˜¯â€œåˆ›å»ºå…³äºç”¨æˆ·è¾“å…¥çš„{topic}çš„æ–°é—»é€šè®¯ã€‚â€*

* **search\_agent** å°†ä½¿ç”¨â€œSerper APIå·¥å…·â€æœç´¢å¹¶è¿”å›å…³äº{topic}çš„5ä¸ªURLã€‚
* **download\_agent** å°†ä½¿ç”¨â€œä¸‹è½½â€å·¥å…·ä¸‹è½½ä¸Šè¿°æ¯ä¸ªURLçš„å†…å®¹ã€‚
* **summary\_agent** å°†ä½¿ç”¨â€œåˆ›å»ºæ–°é—»é€šè®¯â€å·¥å…·ä»æ–‡ç« æ‘˜è¦åˆ—è¡¨å’ŒURLåˆ—è¡¨ä¸­åˆ›å»ºæ–°é—»é€šè®¯ã€‚

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*46vTxLjroctChq8DcvZdhQ.png)

# 4. å®æ–½

æˆ‘å°†å¸¦æ‚¨äº†è§£æˆ‘ä»¬ä»£ç çš„ä¸»è¦éƒ¨åˆ†ã€‚

## 4.1. å·¥å…·

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»º3ä¸ªæŠ€èƒ½ï¼ˆæˆ–å·¥å…·ï¼‰

**æœç´¢å·¥å…·ï¼š** æˆ‘ä½¿ç”¨äº†Serper APIä½œä¸ºç¬¬ä¸€ä¸ªå·¥å…·ã€‚è¿™ä¸ªå·¥å…·çš„ç›®çš„æ˜¯æœç´¢å¹¶è¿”å›ä»»ä½•ä¸»é¢˜çš„5ä¸ªç»“æœ


```python
import json
import os

import requests
from langchain.tools import tool

os.environ["SERPER_API_KEY"] = "799fab83yyyyy"

class SearchTools():

    @tool("search_internet")
    def search_internet(query):
        """ç”¨äºæœç´¢äº’è”ç½‘
        å…³äºç»™å®šä¸»é¢˜å¹¶è¿”å›ç›¸å…³ç»“æœ"""
        print(f"DEBUG:SearchTools:{query}")
        top_result_to_return = 5

        try:
            url = "https://google.serper.dev/search"
            payload = json.dumps({"q": query})
            headers = {
                'X-API-KEY': os.environ['SERPER_API_KEY'],
                'content-type': 'application/json'
            }
            response = requests.request("POST", url, headers=headers, data=payload)
            # æ£€æŸ¥æ˜¯å¦æœ‰organicé”®
            if 'organic' not in response.json():
                return "æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°å…³äºè¯¥ä¸»é¢˜çš„ä»»ä½•ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯æ‚¨çš„serper apiå¯†é’¥æœ‰è¯¯ã€‚"
            else:
                results = response.json()['organic']
                string = []
                for result in results[:top_result_to_return]:
                    try:
                        string.append('\n'.join([
                            f"æ ‡é¢˜: {result['title']}", f"é“¾æ¥: {result['link']}",
                            f"æ‘˜è¦: {result['snippet']}", "\n-----------------"
                        ]))
                    except KeyError:
                        next

                return '\n'.join(string)
        except Exception as e:
            return f"SearchTools:Exception:{e}"


```
**å†…å®¹ä¸‹è½½å·¥å…·ï¼š** æˆ‘ä½¿ç”¨äº†newspaper4kåº“ä½œä¸ºç¬¬äºŒä¸ªå·¥å…·ã€‚è¿™ä¸ªå·¥å…·çš„ç›®çš„æ˜¯ä¸‹è½½å¹¶æ€»ç»“ä¸‹è½½çš„å†…å®¹ï¼Œç”Ÿæˆ150å­—çš„æ–‡æœ¬ã€‚


```python
from crewai import Agent, Task, Crew, Process
import re
from langchain.tools import tool
import newspaper

class BrowserTools():    

    @tool("using_newspaper4k_scrape_and_summarize_website")
    def using_newspaper4k_scrape_and_summarize_website(website):
        """ç”¨äºæŠ“å–å’Œæ€»ç»“ç½‘ç«™å†…å®¹"""
        print(f"DEBUG:BrowserTools:{type(website)}:URL:{website}")
        try:
            link = ""
            if isinstance(website, dict):
                # æ£€æŸ¥å¹¶ä»ç½‘ç«™è·å–é“¾æ¥
                link = website.get("website")["title"]
            else:
                # websiteæ˜¯å­—ç¬¦ä¸²
                pattern = r'"website":\s*"([^"]+)"'
                match = re.search(pattern, website)

                if match:
                    link = match.group(1)
                else:
                    url_pattern = r'https?://[^\s<>"]+|www\.[^\s<>"]+'
                    url_match = re.match(url_pattern, website)
                    if url_match:
                        link = website
                    else:
                        print("æœªæ‰¾åˆ°é“¾æ¥")
            print(f"DEBUG:URL:{link}")

            article = newspaper.article(link)
            content = f"æ ‡é¢˜: {article.title}. å†…å®¹: {article.text}"

            summary_agent = Agent(
                role='æ‘˜è¦ä»£ç†',
                goal='åœ¨150å­—ä»¥å†…æ€»ç»“ä»¥ä¸‹å†…å®¹: {content}',
                backstory="æ‚¨æ˜¯ä¸€ä½è‘—åCEOçš„åŠ©æ‰‹",
                allow_delegation=False,
            )

            summary_task = Task(
                description="åœ¨150å­—ä»¥å†…æ€»ç»“ä»¥ä¸‹å†…å®¹: {content}",
                expected_output="ä¸€ä¸ªæ‘˜è¦",
                agent=summary_agent,
            )

            crew = Crew(
                agents=[summary_agent],
                tasks=[summary_task],
            )
            result = crew.kickoff(inputs={"content": content})
            return result
        except Exception as e:
            return f"BrowserTools:Exception:{e}"
```
**æ‘˜è¦å·¥å…·ï¼š** è¿™ä¸ªå·¥å…·çš„ç›®çš„æ˜¯æ±‡æ€»æ‰€æœ‰æ‘˜è¦å†…å®¹


```python
from langchain.tools import tool

class NewsletterTools():

    @tool("create_newsletter")
    def create_newsletter(summaries):
        """
        åœ¨åˆ›å»ºæ±‡æ€»æ‰€æœ‰æ‘˜è¦å†…å®¹çš„æ–°é—»é€šè®¯æ—¶éå¸¸æœ‰ç”¨
        """
        print(f"DEBUG:NewsletterTools:{summaries}")
        try:
            newsletter = ""
            for summary in summaries:
                # å‡è®¾æ¯ä¸ªæ‘˜è¦éƒ½åŒ…å«'title'å’Œ'content'
                title = summary['title']
                content = summary['description'][:150]  # æ‘˜è¦ä¸è¶…è¿‡150å­—
                newsletter += f"æ ‡é¢˜: {title}\nå†…å®¹: {content}\n\n"
            return newsletter
        except Exception as e:
            return f"NewsletterTools:Exception:{e}"


```

## 4.2. ä»£ç†

è¿™å¾ˆç®€å•ï¼Œå¯¹å§ï¼

* **search\_agent** å°†ä½¿ç”¨â€œæœç´¢å·¥å…·â€æœç´¢å¹¶è¿”å› 5 ä¸ª URL
* **download\_agent** å°†ä½¿ç”¨â€œä¸‹è½½â€å·¥å…·ä¸‹è½½ä¸Šè¿°æ¯ä¸ª URL çš„å†…å®¹ã€‚
* **summary\_agent** å°†æ ¹æ®æ–‡ç« æ‘˜è¦åˆ—è¡¨å’Œ URL åˆ—è¡¨åˆ›å»ºæ–°é—»é€šè®¯


```python
# Define Search Agent
search_agent = Agent(
    role='Search Agent',
    goal="Search for the latest news about the topic {topic}",
    backstory="You are an expert at searching for information on the internet and always keep up with the latest news.",
    memory = True,
    verbose = True,
    callbacks=[MyCustomHandler("SearchAgent")],
    tools = [SearchTools.search_internet]
)

# Define Download Agent
download_agent = Agent(
    role='Download Agent',
    goal="Download and summarize the main content from the list of URL",
    backstory="You are an expert at downloading and summarizing content from articles on the internet.",
    memory=True,
    verbose=True,
    callbacks=[MyCustomHandler("DownloadAgent")],
    tools = [BrowserTools.using_newspaper4k_scrape_and_summarize_website]
)

# Define Newsletter Agent
newsletter_agent = Agent(
    role='Newsletter Agent',
    goal='Create a newsletter aggregating news from a list of article summaries',
    backstory='You are an expert at aggregating news and creating engaging and easy-to-read newsletters.',
    callbacks=[MyCustomHandler("NewsletterAgent")],
    memory=True,
    verbose=True,
    tools = [NewsletterTools.create_newsletter]
)
```

## 4.3. ä»»åŠ¡

æˆ‘ä»¬å°†ç›®æ ‡åˆ†è§£ä¸º 3 ä¸ªä»»åŠ¡ï¼š


```python
# search_task: search for topic via internet
search_task = Task(
    description=(
        "Search and return a list of URLs related to the topic: {topic}."
    ),
    expected_output='List of URLs.',
    agent=search_agent,
)

# download_task: download the content from each received URL
download_task = Task(
    description=(
        "Download content from each URL in the list and summarize the main content of each URL"
    ),
    expected_output='A summary of the main content of URL',
    agent=download_agent,
    context = [search_task]
)

# create_newsletter_task: aggregating the summary results from download_task
create_newsletter_task = Task(
    description=(
        "Create a newsletter from a list of article summaries and the URL list"
    ),
    expected_output='A newsletter aggregating articles including a title and brief description.',
    context = [search_task, download_task],
    agent=newsletter_agent,
)
```

## 4.4. å¦‚ä½•åœ¨ Streamlit ä¸Šå±•ç¤ºæˆ‘ä»¬çš„ç»“æœ

æˆ‘ä»¬å¦‚ä½•åœ¨ Streamlit ä¸Šå±•ç¤ºæˆ‘ä»¬çš„ç»“æœï¼Ÿ


```python
# Avatar Photos for our bots
avatars = {"SearchAgent": "https://cdn-icons-png.flaticon.com/512/10885/10885144.png",
           "DownloadAgent": "https://cdn-icons-png.flaticon.com/512/4021/4021729.png",
           "NewsletterAgent": "https://cdn-icons-png.flaticon.com/512/5822/5822082.png"}

# Init Session State
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "æ‚¨æ„Ÿå…´è¶£çš„è¯é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ"}]


# Handle responses from CrewAI and show it on streamlit chat_message
class MyCustomHandler(BaseCallbackHandler):
    def __init__(self, agent_name: str) -> None:
        self.agent_name = agent_name

    def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any) -> None:
        """æ‰“å°å‡ºæˆ‘ä»¬æ­£åœ¨è¿›å…¥ä¸€ä¸ªé“¾ã€‚
        å¦‚æœè§‰å¾—å¤ªåµï¼Œå¯ä»¥å…³é—­å®ƒ
        """
        # content = "DEBUG: Show you behind stories..:" + inputs['input']
        # st.session_state.messages.append({"role": "assistant", "content": content})
        # st.chat_message("assistant").write(content)

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> None:
        """æ‰“å°å‡ºæˆ‘ä»¬å®Œæˆäº†ä¸€ä¸ªé“¾ã€‚"""
        st.session_state.messages.append({"role": self.agent_name, "content": outputs['output']})
        st.chat_message(self.agent_name, avatar=avatars[self.agent_name]).write(outputs['output'])
```
ä¸»é¡µï¼š


```python
def main_page():
    st.title("ğŸ’¬ CrewAI: åˆ›å»ºæ–°é—»é€šè®¯")

    agents = [search_agent, download_agent, newsletter_agent]
    tasks = [search_task, download_task, create_newsletter_task]

    for msg in st.session_state.messages:
        if msg["role"] in avatars.keys():
            st.chat_message(msg["role"], avatar=avatars[msg["role"]]).write(msg["content"])
        else:
            st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

        crew = Crew(
            agents=agents,
            tasks=tasks,
            process=Process.sequential,
            manager_llm=llm,
            output_log_file="crewai.log",
        )

        final = crew.kickoff(inputs={"topic": prompt})


if __name__ == '__main__':
    main_page()
```

# 5. ç»“æœä¸æœªæ¥å·¥ä½œ

è¿è¡Œä¸Šè¿°ä»£ç å¹¶è·å¾—ç»“æœï¼š

**search\_agent** è¿”å›çš„ç»“æœï¼š

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*P72LQRQXOVbGfhrAdqtoIQ.png)

**download\_agent** è¿”å›çš„ç»“æœï¼š

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*04k7Fx0dhrAJHV1vsjDkvw.png)

æœ€åï¼Œæˆ‘ä»¬çš„ç»“æœï¼ˆæ¥è‡ª newsletter\_agentï¼‰ï¼š

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*QSfkO0A64jEfnZ3XnXt3MA.png)

# æœªæ¥å·¥ä½œ

æˆ‘å¸Œæœ›ä½ åˆ°ç›®å‰ä¸ºæ­¢äº«å—è¿™ä¸ªæ—…ç¨‹ã€‚è¿˜æœ‰è®¸å¤šæƒ³æ³•å¯ä»¥è€ƒè™‘å¹¶ä¸ CrewAI å®ç°ã€‚

ä»¥ä¸‹æ˜¯å…¶ä¸­ä¹‹ä¸€ï¼š

## åŠ å¯†åˆ†æ

ä»¥ä¸‹æ˜¯ä¸€äº›å…³äºå¦‚ä½•ä½¿ç”¨ CrewAI æ„å»ºåŠ å¯†äº¤æ˜“æ•°æ®åˆ†æåº”ç”¨ç¨‹åºçš„æƒ³æ³•ï¼ŒåŒ…æ‹¬ä»£ç†å’Œä»»åŠ¡å®šä¹‰ã€‚

**ä»£ç†æƒ³æ³•**

**1) å¸‚åœºæ•°æ®æ”¶é›†å™¨**

* **è§’è‰²**ï¼šä»å„ç§æ¥æºæ”¶é›†å¸‚åœºæ•°æ®ã€‚
* **ç›®æ ‡**ï¼šæ”¶é›†åŠ å¯†äº¤æ˜“æ‰€çš„ä»·æ ¼ã€äº¤æ˜“é‡å’ŒæŠ€æœ¯æŒ‡æ ‡ã€‚
* **èƒŒæ™¯æ•…äº‹**ï¼šåœ¨åŠ å¯†å¸‚åœºæ–¹é¢çš„ä¸“å®¶ï¼Œèƒ½å¤Ÿå¿«é€Ÿæ”¶é›†å’Œå¤„ç†æ•°æ®ã€‚

**2) æ–°é—»åˆ†æå¸ˆ**

* **è§’è‰²**ï¼šåˆ†æä¸åŠ å¯†ç›¸å…³çš„æ–°é—»ã€‚
* **ç›®æ ‡**ï¼šæ€»ç»“ä¸åŠ å¯†ç›¸å…³çš„æ–°é—»æ–‡ç« ã€æ–°é—»ç¨¿å’Œå¸‚åœºåˆ†æã€‚
* **èƒŒæ™¯æ•…äº‹**ï¼šä¸€ä½æ–°é—»ä¸“å®¶ï¼Œèƒ½å¤Ÿå¿«é€Ÿå‡†ç¡®åœ°åˆ†æå½±å“åŠ å¯†å¸‚åœºçš„æ–°é—»ã€‚

**3) æŠ€æœ¯åˆ†æå¸ˆ**

* **è§’è‰²**ï¼šè¿›è¡ŒæŠ€æœ¯åˆ†æã€‚
* **ç›®æ ‡**ï¼šåˆ†æä»·æ ¼å›¾è¡¨å’ŒæŠ€æœ¯æŒ‡æ ‡ä»¥é¢„æµ‹å¸‚åœºè¶‹åŠ¿ã€‚
* **èƒŒæ™¯æ•…äº‹**ï¼šä¸€ä½æ‹¥æœ‰å¤šå¹´é˜…è¯»å›¾è¡¨å’ŒæŒ‡æ ‡ç»éªŒçš„æŠ€æœ¯åˆ†æä¸“å®¶ã€‚

**4) æƒ…ç»ªåˆ†æå¸ˆ**

* **è§’è‰²**ï¼šåˆ†æå¸‚åœºæƒ…ç»ªã€‚
* **ç›®æ ‡**ï¼šé€šè¿‡ç¤¾äº¤åª’ä½“å’Œè®ºå›åˆ†æå¸‚åœºæƒ…ç»ªï¼Œä»¥è¯„ä¼°æŠ•èµ„è€…æƒ…ç»ªã€‚
* **èƒŒæ™¯æ•…äº‹**ï¼šä¸€ä½æƒ…ç»ªåˆ†æä¸“å®¶ï¼Œèƒ½å¤Ÿä»ç¤¾äº¤æ•°æ®æºä¸­è¯»å–å¸‚åœºæƒ…ç»ªã€‚

**5) æŠ•èµ„ç­–ç•¥å¸ˆ**

* **è§’è‰²**ï¼šåˆ¶å®šæŠ•èµ„ç­–ç•¥ã€‚
* **ç›®æ ‡**ï¼šç»“åˆå…¶ä»–ä»£ç†çš„åˆ†æï¼Œæä¾›å…¨é¢çš„æŠ•èµ„å»ºè®®ã€‚
* **èƒŒæ™¯æ•…äº‹**ï¼šä¸€ä½æŠ•èµ„ç­–ç•¥å¸ˆï¼Œèƒ½å¤Ÿç»“åˆå¤šä¸ªæ¥æºçš„ä¿¡æ¯åšå‡ºæ˜æ™ºçš„æŠ•èµ„å†³ç­–ã€‚

**ä»»åŠ¡æƒ³æ³•**

æ”¶é›†å¸‚åœºæ•°æ®


```python
from crewai import Task

market_data_task = Task(
    description="""
    Collect market data from crypto exchanges, including prices, trading volumes, and technical indicators.
    """,
    expected_output="A dataset containing prices, trading volumes, and technical indicators from exchanges.",
    agent=market_data_collector
)
```
åˆ†æåŠ å¯†æ–°é—»


```python
from crewai import Task

news_analysis_task = Task(
    description="""
    Summarize news articles, press releases, and market analyses related to crypto.
    """,
    expected_output="A report summarizing the latest news, press releases, and market analyses related to crypto.",
    agent=news_analyzer

)
```
è¿›è¡ŒæŠ€æœ¯åˆ†æ


```python
from crewai import Task

technical_analysis_task = Task(
    description="""
    Analyze price charts and technical indicators to predict market trends.
    """,
    expected_output="A technical analysis report including price charts and market trend predictions.",
    agent=technical_analyst
)
```
è¯„ä¼°å¸‚åœºæƒ…ç»ª


```python
from crewai import Task

sentiment_analysis_task = Task(
    description="""
    Analyze market sentiment through social media and forums to gauge investor sentiment.
    """,
    expected_output="A report analyzing market sentiment from social media and forums.",
    agent=sentiment_analyst
)
```
åˆ¶å®šæŠ•èµ„ç­–ç•¥ï¼š


```python
from crewai import Task

investment_strategy_task = Task(
    description="""
    Combine analyses from other agents to provide comprehensive investment recommendations.
    """,
    expected_output="A comprehensive investment strategy report combining technical analysis, news analysis, and sentiment analysis.",
    agent=investment_strategist,
    context=[market_data_task, news_analysis_task, technical_analysis_task, sentiment_analysis_task]
)
```
**å›¢é˜Ÿ**


```python
from crewai import Crew

# Create a Crew with the agents and tasks
crypto_analytics_crew = Crew(
    agents=[market_data_collector, news_analyzer, technical_analyst, sentiment_analyst, investment_strategist],
    tasks=[market_data_task, news_analysis_task, technical_analysis_task, sentiment_analysis_task, investment_strategy_task]
)

# Kick off the Crew with specific input information
result = crypto_analytics_crew.kickoff(inputs={"input": "Bitcoin"})
print(result)
```

## åœ¨ä½ ç¦»å¼€ä¹‹å‰ï¼ğŸ¤Ÿ

å¦‚æœä½ è§‰å¾—è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©å¹¶å¸Œæœ›è¡¨ç¤ºæ”¯æŒï¼Œ**è¯·ä¸ºæˆ‘çš„æ–‡ç« é¼“æŒ 10 æ¬¡ã€‚** ğŸ‘ è¿™çœŸçš„ä¼šæ¿€åŠ±æˆ‘ï¼Œå¹¶å°†è¿™ç¯‡æ–‡ç« æ¨èç»™æ›´å¤šäººã€‚

# Stackademic ğŸ“

æ„Ÿè°¢æ‚¨é˜…è¯»åˆ°æœ€åã€‚åœ¨æ‚¨ç¦»å¼€ä¹‹å‰ï¼š

* è¯·è€ƒè™‘ **ç‚¹èµ** å’Œ **å…³æ³¨** ä½œè€…ï¼ ğŸ‘
* å…³æ³¨æˆ‘ä»¬ [**X**](https://twitter.com/stackademichq) | [**LinkedIn**](https://www.linkedin.com/company/stackademic) | [**YouTube**](https://www.youtube.com/c/stackademic) | [**Discord**](https://discord.gg/in-plain-english-709094664682340443)
* è®¿é—®æˆ‘ä»¬çš„å…¶ä»–å¹³å°ï¼š [**In Plain English**](https://plainenglish.io/) | [**CoFeed**](https://cofeed.app/) | [**Differ**](https://differ.blog/)
* æ›´å¤šå†…å®¹è¯·è®¿é—® [**Stackademic.com**](https://stackademic.com/)
