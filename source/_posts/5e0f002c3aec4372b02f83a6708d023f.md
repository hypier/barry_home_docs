
---
categories: 人工智能
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*BvXjSudm4uJyc8cTa0QrSA.png
date: '2024-08-05 06:47:40'
tags:
  - 工程仿真
  - AI代理
  - 语言模型
title: 利用 Gen AI 进行工程设计 — 自主 LLM 代理解决固体力学和流体动力学问题

---
## 使用 Microsoft AutoGen 和 GPT-4o 的工程仿真对话代理，最小化人类输入。（带 GitHub 代码）

用于执行工程仿真的对话多代理框架的图形摘要。注意：仿真图像仅用于说明目的。

设想一个未来，AI 通过简单的对话轻松解决工程问题。下一代 AI 和语言模型将彻底改变我们使用有限元分析（FEA）和计算流体动力学（CFD）等工程工具来解决结构分析、热力学、气动学、电场和电磁势等复杂问题的方式。很快，掌握这些工具将不再需要用户在力学、数学、材料、物理或编程方面的广泛专业知识。

当今的大型语言模型（LLMs）和生成 AI 工具能够模拟人类行为，例如自然语言处理、模式识别、记忆保留、批判性思维、推理和决策。他们还可以在 C++、Python、Julia 和 MATLAB 中编写和调试数值算法。超越语言，他们是对话 AI 代理背后的大脑，使 AI 与人类及 AI 与工具的交互更加顺畅和有效。多个代理可以协作计划和执行任务，监控输出，适应并使用工具自主实现目标。通过结合这些能力，工程师将能够通过简单的对话与强大的数值仿真工具互动，并在最小干预下解决工程问题。

在这些进展的基础上，在本文中，我将演示如何构建一个由 LLM 驱动的 AI 代理网络，这些代理能够在最小人类输入的情况下自主创建模型并模拟固体力学和流体动力学中的问题。我们使用 **Microsoft AutoGen** 设置了一组对话代理，每个代理在规划、问题表述、编写、调试和执行代码、绘图和分析以及结果评估等角色中都是专家。他们将自主工作，必要时相互纠正，以使用开源 Python 库创建和模拟 FEA 和 CFD 模型。**OpenAI 的 GPT-4 是** 背后的强大动力。该框架被封装在使用 **Chainlit** 应用程序的用户界面中。

以下是该应用程序在实际运行中的样子。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*hXsmO67FmpyfUec6SYK0Ug.png)使用 Python 编码解决 CFD 问题的多代理任务和对话示例

## 示例案例和提示

我在各种标记为 (a)-(d) 的 2D FEA 和 CFD 问题以及一个标记为 (e) 的 3D FEA 问题上测试了该应用程序。下面是代理生成的相应图形，以及它们的初始用户提示。

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*mtR9CbSQfcVuCAHnwUfh1g.png)

以下是我为上述五个示例使用的提示。

## a) 2D 板在位移下

> 一块 1m x 1m 的弹性板的杨氏模量为 1GPa，泊松比为 0.3。左边缘的位移为零，右边缘在 x 方向的位移为 0.1m。使用 FENICS 求解位移，并将位移结果存储在 PNG 文件中。

## b) 带有圆孔的位移板

> 一个2D板占据1m x 1m的区域。它由铜制成，中间有一个半径为0.2m的圆孔。左边缘的位移为零，右边缘沿x方向的位移为0.02m。上下边缘可以自由移动。请使用FENICS求解位移，绘制并将von Mises应力存储为PNG文件，并计算右边缘的总力。

## c) 2D 不可压缩流体在矩形通道中的流动

> 求解在一个长度为 2m、高度为 0.5m 的矩形通道内的 2D 不可压缩流体流动。流体密度为 1，粘度为 0.001。在左侧入口处规定一个充分发展的抛物线速度分布，最大速度为 0.3。使用 FEniCS FE Python 库求解 2D 压力和速度场。绘制压力场并将图保存为 PNG 文件。

```
# Code block remains unchanged
```

## d) 通过具有圆形障碍物的矩形通道的二维流动

> 求解在长度为2m、高度为0.5m的矩形通道内，圆柱体上方的二维不可压流动。圆柱体位于(0.2m, 0.2m)处，直径为0.1m。流体密度为1，粘度为0.001。在左侧入口处规定完全发展的抛物线速度分布，最大速度为0.3。使用FEniCS FE Python库求解二维压力和速度场。绘制压力场并将图保存为PNG文件。

## e) 3D 空心钢管在内压下

> 创建一个外径为 5 mm、壁厚为 0.5 mm 的 3D 钢管网格。首先绘制网格并与用户进行验证。使用 FEniCS FE python 库求解钢管在 100 MPa 内压下的位移。使用 Pyvista 绘制并显示 3D 位移。将图形保存为 PNG 文件。

请注意，这些并不是即时解决方案。有时，我与代理进行了多次反复的对话，经过迭代直到我们解决了问题。例如，问题 (b) 涉及一个带有中心圆孔的板。最初，几何形状缺少孔，但经过几次迭代后，我们进行了修正。同样，CFD 问题缺少一个圆形障碍物，我们通过调试解决了这个问题。3D 问题需要最多的迭代，包括关闭并重新打开应用程序以从头开始。我还调整了输入提示，以更好地指导模型开发过程。总体而言，我对结果感到非常满意。这只是 LLM 驱动的代理如何编写、调试和执行工程代码以进行建模和模拟任务的开始。

该开发是在 Linux 环境中使用 Windows 子系统 Linux (WSL) 和 Windows 11 PC 上的 Visual Studio Code 进行的，配备 Intel i9 第 13 代处理器、64 GB RAM 和 24 GB Nvidia RTX 4090。我尚未在本机 Windows 环境中进行测试，但欢迎您自行尝试。有关安装 WSL 和设置 Python 及 Conda 环境的指南，请参阅本文（ [这里](https://robkerr.ai/fine-tuning-llms-using-a-local-gpu-on-windows/)）。

这是源代码库的 [链接](https://github.com/karthik-codex/autogen_FEA)。

如果您读到这里，请为这篇文章鼓掌。敬请关注更多见解和改进。现在，让我们开始使用和修改代码。

## 安装指南

该实现的核心涉及使 AI 代理能够利用开源 Python 库和工具。为了求解 FEA 或 CFD 问题，我们需要工具来编写几何体脚本，使用数值算法求解，并可视化结果。像 gmsh 这样的库是一个三维有限元网格生成器，具有内置的前处理和后处理功能，用于创建几何体或网格。FEniCS 是一个开源计算平台，用于求解偏微分方程（PDE），用于制定和运行数值模拟。对于可视化，使用 matplotlib 处理 2D 几何，使用 pyvista 处理 3D 几何。其他所需的库列在我的 GitHub 仓库中的 `requirements.txt` 文件中。

在创建应用程序时，我将安装限制为 AutoGen 和 Chainlit。通常，代理可以根据您要求它们解决的问题自动安装所有其他必要的库。然而，这通常会消耗额外的令牌和 API 调用，有时效率不高。因此，我预先安装了这些库，因为我知道它们将是必需的。

> 记住，您需要 ChatGPT 的 GPT-4o 的 API 密钥。如果您的硬件允许，您可以尝试使用像 Llama3:405B 这样的强大离线模型。较小的模型尚不可用。

## 安装和启动应用程序的终端命令

从 conda-forge 通道安装 FEniCS 也会安装兼容的 Python 版本，因此我们不需要指定它。

```
conda create -n fea_agents -c conda-forge fenics mshr

conda activate fea_agents

git clone https://github.com/karthik-codex/autogen_FEA.git

cd autogen_FEA

pip install -r requirements.txt

export API_KEY=<your_key_xxxxxx>

chainlit run appUI.py
```

您将在我的 GitHub 仓库中找到以下文件。

1. `./requirements.txt`— _包含上述所有软件包的列表_
2. `./chainlit_agents.py`— _包含类定义，包括 AutoGen 的助手和用户代理。这允许跟踪多个代理并在 UI 中显示它们的消息。 (感谢 Chainlit 团队构建的 [模板](https://github.com/Chainlit/cookbook/blob/main/pyautogen))。_
3. `./appUI.py`— _包含设置代理、跟踪和处理消息以及在 Chainlit UI 中显示它们的主要异步函数。_

## 主 Python 应用程序结构

## 导入库

您会注意到从 _chainlit\_agents_ 中导入了两个类。这些 AutoGen 代理的包装类使 Chainlit 能够跟踪它们的对话，以适当的格式显示文本和代码，并处理终止或其他用户输入。您可以在 [这里](https://readmedium.com/autogen-web-application-using-chainlit-8c5ebf5a4e75) 阅读更多信息。

```
import os
import autogen
import chainlit as cl
from chainlit_agents import ChainlitUserProxyAgent, ChainlitAssistantAgent
```

## 加载 LLM 配置

将您的 API 密钥导出到您的操作系统环境中，或直接将其作为字符串变量粘贴到代码中。

```
api_key = os.getenv('API_KEY')

config_list_openai = [
    {"model": "gpt-4o", "api_key": api_key}
]

llm_config = {
    "seed": 565,
    "temperature": 0,
    "config_list": config_list_openai,
    "timeout": 60000,
}
```

## 为代理创建系统消息。

我们设计具有特定角色的代理：管理员（admin）、规划者、科学家、工程师、执行者、评论员和群聊管理者，并将它们组织成一个研究小组，以实现自主、互动和动态的群聊。每个代理的角色通过代理配置来定义，使用初始提示来影响LLMs在聊天过程中的行为。

1. 管理员分配任务并在请求时提供见解。
2. 规划者制定逐步计划并建议其他代理的具体子任务。
3. 科学家使用有限元法（FEM）来制定力学问题。
4. 工程师编写和调试实现代码。
5. 执行者运行脚本，访问模拟环境并分享结果。
6. 评论员对过程和代理的表现提供评估。
7. 群聊管理者通过选择发言者、收集输入和广播消息来协调对话。

以下是每个代理的系统提示。

```
USER_PROXY_MESSAGE = '''A human admin. Interact with the planner to discuss the plan.
Plan execution needs to be approved by this admin.'''

ENGINEER_MESSAGE = '''Engineer. You follow an approved plan. You write Python/shell code to solve tasks.
Wrap the code in a code block that specifies the script type. The user can't modify your code.
So do not suggest incomplete code which requires others to modify. Don't use a code block if it's
not intended to be executed by the executor. Don't include multiple code blocks in one response.
Do not ask others to copy and paste the result. Check the execution result returned by the executor.
If the result indicates there is an error, fix the error and output the code again.
Suggest the full code instead of partial code or code changes. If the error can't be fixed or if
the task is not solved even after the code is executed successfully, analyze the problem,
revisit your assumption, collect additional info you need, and think of a different approach to try.
In the code you write, always add a part to report the solution on the boundaries and store it in a separate file for the Scientist to check.'''

PLANNER_MESSAGE = """Planner. Suggest a plan. Revise the plan based on feedback from admin and critic, until admin approval.
The plan may involve an engineer who can write code and a scientist who doesn't write code.
Explain the plan first. Ask the Executor to install any Python libraries or modules as needed without human input.
Be clear which step is performed by an engineer, and which step is performed by a scientist."""

SCIENTIST_MESSAGE = """Scientist. You follow an approved plan. You can formulate the mechanics problem with
clear boundary conditions and constitutive law of materials. You don't write code. You explicitly check the
boundary results from the Engineer to see whether it agrees with the input boundary conditionand geometry.
When you execute the code, always save a copy for review."""

EXECUTOR_MESSAGE = """Executor. Save and execute the code written by the engineer and report and save the result.
Use both shell and python language interpreter."""

CRITIC_MESSAGE = """ Critic. Double check plan, claims, code from other agents, results on the boundary conditions, and provide feedback.
Check whether the plan includes adding verifiable info such as source URL."""

## Chainlit UI 的启动功能

当用户打开聊天应用程序时，我们创建代理并打印欢迎消息。执行器运行脚本，访问模拟环境并共享结果。因此，我们启用代码执行配置，并将 docker 设置为 False，以仅使用本地操作系统环境进行代码执行。

```
@cl.on_chat_start
async def on_chat_start():
  try:
    print("Set agents.")
    user_proxy  = ChainlitUserProxyAgent("Admin", system_message=USER_PROXY_MESSAGE, code_execution_config=False)
    engineer    = ChainlitAssistantAgent("Engineer", llm_config=llm_config, system_message=ENGINEER_MESSAGE)
    scientist   = ChainlitAssistantAgent("Scientist", llm_config=llm_config, system_message=SCIENTIST_MESSAGE)
    planner     = ChainlitAssistantAgent("Planner",llm_config=llm_config, system_message=PLANNER_MESSAGE)
    critic      = ChainlitAssistantAgent("Critic", llm_config=llm_config, system_message=CRITIC_MESSAGE)
    executor    = ChainlitAssistantAgent("Executor", system_message=EXECUTOR_MESSAGE, human_input_mode="NEVER",
                                    code_execution_config={"last_n_messages": 3, "work_dir": "FEA_results","use_docker": False})

    cl.user_session.set("user_proxy", user_proxy)
    cl.user_session.set("engineer", engineer)
    cl.user_session.set("scientist", scientist)
    cl.user_session.set("planner", planner)
    cl.user_session.set("critic", critic)
    cl.user_session.set("executor", executor)

    msg = cl.Message(content=f"""Hello! What simulation task would you like to get done today?
                     """,
                     author="User_Proxy")
    await msg.send()

  except Exception as e:
    print("Error: ", e)
    pass
```

## 对话功能

为了测试这个多代理组自主解决工程问题的能力，我们仅使用管理员代理（用户代理）来分配任务。虽然在各个阶段收集人类输入是可能的，但我们在小组聊天期间跳过人类输入。您可以增加变量 `MAX_ITER` 来根据您尝试解决的问题的复杂性来增加代理之间的对话次数。

```
@cl.on_message
async def run_conversation(message: cl.Message):
    MAX_ITER = 50
    CONTEXT = message.content
    user_proxy  = cl.user_session.get("user_proxy")
    planner     = cl.user_session.get("planner")
    engineer    = cl.user_session.get("engineer")
    critic      = cl.user_session.get("critic")
    executor    = cl.user_session.get("executor")
    scientist   = cl.user_session.get("scientist")
    groupchat   = autogen.GroupChat(agents=[user_proxy, planner, engineer, scientist, executor, critic],
                                    messages=[], max_round=MAX_ITER)
    manager     = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)

    print("Running conversation")
    await cl.make_async(user_proxy.initiate_chat)( manager, message=CONTEXT, )
```

这就是主要代码的结束部分。

## 我的最终想法

这个多智能体 LLM 框架展示了通过利用 ChatGPT 的广泛知识和开源工具，超越仅依赖人类的范式来解决工程问题的潜力。这种方法的准确性和效率依赖于 LLM 对固体力学、流体动力学、多物理场理论、材料科学和编码的深刻理解。一个更专业、经过精细调整的 LLM，如果在大量相关科学文献和编码数据集上进行训练，可能会产生更准确的结果。使模型能够编写和执行复杂的工程代码和算法至关重要。

可以创建额外的智能体来处理特定的子任务，以增强这种方法。例如，一个智能体可以生成初始几何形状或 CAD 文件，另一个可以进行网格划分，第三个可以编写数值算法。这种劳动分工减少了错误，并最小化了解决问题所需的迭代和群聊对话。

此外，这些自主智能体可以使用 API 与商业工程软件（如 SOLIDWORKS、ANSYS、Abaqus 和 LS-DYNA）进行交互。训练 LLM 为这些 API 编写脚本将促进顺畅的交互。这种方法自动化了工程设计和分析问题的解决，铺平了人类与 AI 在工程研究和创新中无缝协作的道路。

> **关于我**：我是 Eaton Research Labs（美国密歇根州南菲尔德）的首席建模工程师。我探索、开发工具，并撰写有关计算力学、材料科学、工程、语言模型和生成 AI 交叉领域的内容。

如果您想保持更新，请关注我下面的社交媒体。

社交媒体：[LinkedIn](https://github.com/karthik-codex/autogen_FEA)，[GitHub](https://github.com/karthik-codex)，[源代码](https://github.com/karthik-codex/autogen_graphRAG.git)
