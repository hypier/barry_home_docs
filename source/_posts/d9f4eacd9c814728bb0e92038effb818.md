
---
categories: äººå·¥æ™ºèƒ½
cover: https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*qBjMA7oSGZ2kQajB.jpg
date: '2024-08-19 00:50:04'
tags:
  - AIåº”ç”¨
  - SQLæŸ¥è¯¢
  - æ•°æ®å¤„ç†
title: SQL ç”Ÿæˆå™¨ 2.0æˆ‘å¦‚ä½•ä¸ºä¼ä¸šçº§æ„å»º AI æŸ¥è¯¢å‘å¯¼æ”¯æŒ 500 è¡¨

---


# è¿„ä»Šä¸ºæ­¢çš„æ—…ç¨‹ï¼šConfluence Agentçš„å›é¡¾

åœ¨æˆ‘ä»¬æ·±å…¥æ¢è®¨SQL Agentä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç®€è¦å›é¡¾ä¸€ä¸‹æˆ‘ä»¬å¼€å‘çš„Confluence Agentï¼š

1. **Metadata Ingestion**: æ•æ‰æˆ‘ä»¬çŸ¥è¯†åº“çš„ç»“æ„ã€‚
2. **Content Extraction**: æå–æˆ‘ä»¬æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹ã€‚
3. **Format Handling**: åˆ†ç¦»HTMLå’ŒPDFå†…å®¹ä»¥å®ç°æœ€ä½³å¤„ç†ã€‚
4. **Image Analysis**: åˆ©ç”¨LLMè§£ææå–å’Œç†è§£å›¾åƒå†…å®¹ã€‚
5. **Performance Boost**: å®ç°å¼‚æ­¥å’Œå¤šçº¿ç¨‹å¤„ç†ï¼Œå®ç°10å€çš„é€Ÿåº¦æå‡ã€‚

è¿™äº›å¢å¼ºåŠŸèƒ½ä¸ºå¼ºå¤§çš„ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬æ­£åœ¨æ‰©å±•æˆ‘ä»¬çš„å·¥å…·åŒ…ï¼Œä»¥è§£å†³æ•°æ®é©±åŠ¨ç»„ç»‡ä¸­æœ€å¸¸è§çš„æŒ‘æˆ˜ä¹‹ä¸€ï¼šSQLæŸ¥è¯¢ç”Ÿæˆã€‚

# æˆ‘ä¸ºä»€ä¹ˆè¦æ„å»ºè¿™ä¸ªï¼Ÿ

æƒ³è±¡ä¸€ä¸‹è¿™ä¸ªåœºæ™¯ï¼šä½ æ˜¯ä¸€åæ–°çš„æ•°æ®åˆ†æå¸ˆï¼Œä½ çš„è€æ¿æ€¥åŒ†åŒ†åœ°èµ°åˆ°ä½ çš„æ¡Œå‰ï¼Œæå‡ºä¸€ä¸ªç´§æ€¥è¯·æ±‚ï¼š

> *â€œæˆ‘éœ€è¦å¯¹æ˜¨å¤©çš„æ¸¸æˆæŒ‡æ ‡ä¸å»å¹´çš„æ•°æ®è¿›è¡Œæ¯”è¾ƒåˆ†æï¼Œé‡ç‚¹å…³æ³¨é€Ÿåº¦å’Œæ”¶å…¥ã€‚è¯·åœ¨ä»Šå¤©ç»“æŸå‰æ”¾åˆ°æˆ‘çš„æ¡Œå­ä¸Šã€‚â€*

å½“ä½ è„¸è‰²è‹ç™½æ—¶ï¼Œä½ æ„è¯†åˆ°ä½ é¢ä¸´å‡ ä¸ªæŒ‘æˆ˜ï¼š

1. ä½ æ˜¯æ–°æ¥çš„ï¼Œä¸çŸ¥é“åœ¨å“ªé‡Œæ‰¾åˆ°ç›¸å…³æ•°æ®ã€‚
2. ä½ ä¸ç¡®å®šå“ªäº›è¡¨åŒ…å«ä½ éœ€è¦çš„ä¿¡æ¯ã€‚
3. ç¼–å†™å¤æ‚çš„ SQL æŸ¥è¯¢è¿˜ä¸æ˜¯ä½ çš„å¼ºé¡¹ï¼ˆè¿˜ä¸æ˜¯ï¼‰ã€‚
4. ä½ çš„ç»ç†æ•´å¤©éƒ½åœ¨å¼€ä¼šï¼Œä½ ä¸æƒ³ç”¨åŸºæœ¬é—®é¢˜æ‰“æ‰°ä»–ä»¬ã€‚

è¿™ä¸ªåœºæ™¯çªæ˜¾äº†è®¸å¤šç»„ç»‡é¢ä¸´çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼š

1. **æ•°æ®é‡**ï¼šåœ¨ä¼ ç»Ÿå’Œç°ä»£æ•°æ®ä»“åº“ä¸­ï¼Œæœ‰è¶…è¿‡ 500 ä¸ªè¡¨ï¼Œæ‰¾åˆ°æ­£ç¡®çš„æ•°æ®å°±åƒåœ¨å¤§æµ·æé’ˆã€‚
2. **æŸ¥è¯¢å¤æ‚æ€§**ï¼šä½œä¸ºå”¯ä¸€çš„çœŸå®æ•°æ®æ¥æºï¼Œéœ€è¦åº”å¯¹æ¥è‡ªå„ä¸ªéƒ¨é—¨çš„å¤æ‚æŸ¥è¯¢ã€‚
3. **çŸ¥è¯†å·®è·**ï¼šæ–°å›¢é˜Ÿæˆå‘˜å¾€å¾€åœ¨æ²¡æœ‰å¹¿æ³›çš„æœºæ„çŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œéš¾ä»¥å¯¼èˆªåºå¤§çš„æ•°æ®åº“ã€‚

æˆ‘æ€è€ƒè¿™ä¸ªé—®é¢˜å·²ç»æœ‰ä¸€æ®µæ—¶é—´ï¼Œä½†ç›´åˆ°ä¸€ä¸ªå®Œå…¨æ­£å¸¸çš„æ—©æ™¨ï¼Œæˆ‘å’Œæˆ‘çš„æ€»ç»ç†è¿›è¡Œäº†ä¸€æ¬¡éšæ„çš„å¯¹è¯ï¼Œæˆ‘æ‰å¼€å§‹è€ƒè™‘ç€æ‰‹è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

> *â€œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä»ä½ çš„èŠå¤©æœºå™¨äººæŸ¥è¯¢æ•°æ®å—ï¼Ÿâ€*

æˆ‘æ²¡æƒ³åˆ°ï¼Œè¿™å¥éšå£è€Œå‡ºçš„è¯„è®ºä¼šè®©æˆ‘è¸ä¸Šæ”¹é©æˆ‘ä»¬ä¸æ•°æ®äº’åŠ¨æ–¹å¼çš„å¾ç¨‹ã€‚ä½†åœ¨æˆ‘è®²è¿°æˆ‘æ˜¯å¦‚ä½•æ„å»ºè¿™ä¸ª AI æŸ¥è¯¢å‘å¯¼ä¹‹å‰ï¼Œè®©æˆ‘å…ˆè°ˆè°ˆä¸ºä»€ä¹ˆå¤§å¤šæ•°ç°æœ‰è§£å†³æ–¹æ¡ˆæ ¹æœ¬æ— æ³•è§£å†³ä¼ä¸šè§„æ¨¡çš„é—®é¢˜ã€‚

# ä¸ºä»€ä¹ˆâ€œåªéœ€è°·æ­Œä¸€ä¸‹â€å¯¹ä¼ä¸š SQL æŒ‘æˆ˜æ— æ•ˆ

åœ¨åŠ¨æ‰‹ä¹‹å‰ï¼Œæˆ‘åšäº†ä»»ä½•ä¸€ä¸ªè‡ªå°Šå¿ƒå¼ºçš„å¼€å‘è€…éƒ½ä¼šåšçš„äº‹æƒ…ï¼šæˆ‘åœ¨äº’è”ç½‘ä¸Šå¯»æ‰¾è§£å†³æ–¹æ¡ˆã€‚æˆ‘å‘ç°çš„å†…å®¹æ˜¯â€¦â€¦å—¯ï¼Œå§‘ä¸”è¯´å®ƒè¿˜å·®å¾—è¿œã€‚

# æ–‡æœ¬åˆ° SQL çš„â€œä½ å¥½ï¼Œä¸–ç•Œâ€

æˆ‘å‘ç°çš„å¤§å¤šæ•°æ–‡ç« å’Œæ•™ç¨‹å°±åƒæ˜¯ç”¨å„¿ç«¥æ¸¸æ³³æ± æ¥è®­ç»ƒå¥¥è¿ä¼šï¼š

* ğŸ£ **å°è¡¨**ï¼šä½¿ç”¨ 2â€“3 ä¸ªè¡¨çš„ç¤ºä¾‹ã€‚å¯çˆ±ï¼Œä½†æˆ‘ä»¬æœ€å°çš„æ¨¡å¼ä¼šæŠŠè¿™äº›å½“æ—©é¤åƒæ‰ã€‚
* ğŸ“œ **æ— é™æç¤ºå·è½´**ï¼šè§£å†³æ–¹æ¡ˆå»ºè®®æˆ‘å°†æ•´ä¸ªè¡¨æ¨¡å¼ç²˜è´´åˆ°æç¤ºä¸­ã€‚ç¥ä½ åœ¨æ— é™æç¤ºä¸­å¥½è¿ã€‚
* ğŸï¸ **å­¤ç«‹å²›æŸ¥è¯¢**ï¼šå¯¹å•ä¸ªè¡¨çš„ç®€å•æŸ¥è¯¢ï¼Œå¿½ç•¥äº†çœŸå®æ•°æ®åº“ä¸­çš„å¤æ‚å…³ç³»ã€‚
* ğŸŒ **æ€§èƒ½ï¼Ÿä»€ä¹ˆæ€§èƒ½ï¼Ÿ**ï¼šå¤§å¤šæ•°ç¤ºä¾‹å¿½è§†äº†åœ¨å¤§æ•°æ®é›†ä¸­çš„æŸ¥è¯¢æ€§èƒ½è¿™ä¸€å…³é”®æ–¹é¢ã€‚

# æˆ‘çš„æ•°æ®ç°å®

åœ¨è¿™äº›æ•™ç¨‹è¿˜åœ¨å°å‹æ¸¸æ³³æ± é‡Œç©è€æ—¶ï¼Œæˆ‘å´åœ¨å‡è§†ç€æ•°æ®ç­‰åŒäºå¤ªå¹³æ´‹çš„æµ©ç€šï¼š

* ğŸ™ï¸ **è¡¨æ ¼æ··ä¹±**ï¼šè¶…è¿‡300ä¸ªè¡¨æ ¼ï¼Œæœ‰äº›è¡¨æ ¼çš„åˆ—æ•°è¶…è¿‡150
* ğŸ•¸ï¸ **å¤æ‚å…³ç³»**ï¼šä¸€ä¸ªå…·æœ‰å¤æ‚ç›¸äº’ä¾èµ–å…³ç³»çš„æ•°æ®æ¨¡å‹ï¼Œå³æ•°æ®ä¿é™©åº“å»ºæ¨¡ã€‚
* ğŸï¸ **é€Ÿåº¦éœ€æ±‚**ï¼šéœ€è¦ä¸ºé€Ÿåº¦å’Œæ•ˆç‡ä¼˜åŒ–çš„æŸ¥è¯¢ã€‚
* ğŸ”„ **æ¼”å˜ä¸­çš„æ¨¡å¼**ï¼šä¸€ä¸ªè¡¨ç»“æ„é¢‘ç¹å˜åŒ–çš„åŠ¨æ€ç¯å¢ƒã€‚

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/0*v-mjPINlzvjZ9p3e.png)

å¾ˆæ˜æ˜¾ï¼šæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸æˆ‘ä»¬çš„æ•°æ®ç¯å¢ƒä¸€æ ·å¼ºå¤§å’Œå¤æ‚çš„è§£å†³æ–¹æ¡ˆã€‚

# å®ç° SQL Agent

è®©æˆ‘ä»¬ä¸æµªè´¹æ—¶é—´ï¼Œç›´æ¥è¿›å…¥ä¸»é¢˜ã€‚ç°åœ¨ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªé™åˆ¶ã€‚

æˆ‘æ˜¾ç„¶å¯ä»¥èµ‹äºˆ SQL Agent æ‰§è¡Œ SQL çš„èƒ½åŠ›ã€‚å®é™…ä¸Šï¼Œæˆ‘åº”è¯¥è¿™æ ·åšï¼Œä½†æ˜¯ï¼Œç”±äºè¿™æ˜¯ä¸€ä¸ªæ¦‚å¿µéªŒè¯ï¼ˆPoCï¼‰ï¼Œä¸æ•°æ®åº“äº¤äº’çš„ API å¯†é’¥åœ¨æˆ‘åä¸‹ï¼Œä»»ä½•äººéƒ½å¯ä»¥è½»æ˜“åœ°è¿›è¡Œæç¤ºæ³¨å…¥ï¼Œæ¯”å¦‚è¯´â€œåˆ é™¤è¡¨â€ã€‚æ­¤å¤–ï¼Œæˆ‘ä¸ä¿è¯ä»ä»£ç†ç”Ÿæˆçš„ SQL æ˜¯ 100% æ­£ç¡®å’Œä¼˜åŒ–çš„ã€‚éšç€è®­ç»ƒæ•°æ®çš„ä¸æ–­å¢åŠ ï¼Œæˆ‘ä»¬æœ€ç»ˆä¼šå¾ˆå¿«è¾¾åˆ°é‚£ä¸ªé˜¶æ®µã€‚ç›®å‰ï¼Œç”¨æˆ·éœ€è¦è‡ªè¡ŒéªŒè¯ç”Ÿæˆçš„ SQLã€‚

## å½“å‰çš„é«˜çº§æ¶æ„

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*RMaWUW6W1KS4iLO3PIo3iQ.png)

æˆ‘ä»¬ç›®å‰åªæœ‰ä¸€ä¸ªå•ä¸€çš„ä»£ç†ã€‚Confluence Agentã€‚å·¥ä½œæµç¨‹ä¿æŒä¸å˜ã€‚ç”¨æˆ·å‘é€è¯·æ±‚ -> è¯·æ±‚å‘é€åˆ°ä¸»ä»£ç†è¿›è¡Œæ¨ç† -> å‘é€åˆ° Confluence Agent ä»¥é€šè¿‡ Confluence çŸ¥è¯†åº“æ‰¾åˆ°ç­”æ¡ˆ -> å‘é€åˆ°éªŒè¯ä»£ç†ä»¥éªŒè¯å“åº” -> å‘é€åˆ°äººå·¥å“åº”ä»£ç†ä»¥æ ‡è®° PII æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰å¹¶å›å¤ç”¨æˆ·ï¼Œå¦åˆ™ï¼Œè°ƒç”¨ä¸»ä»£ç†å¹¶è¯·æ±‚é‡æ–°è¯„ä¼°ï¼Œå› ä¸ºæ•°æ®æ£€ç´¢ä¸å¤Ÿå¥½ã€‚

## æ•°æ®å¤„ç†ï¼šæˆåŠŸçš„åŸºç¡€

å¦‚æœä½ åªæ˜¯å°†çº¯æ–‡æœ¬ç›´æ¥æ”¾å…¥å‘é‡æ•°æ®åº“ï¼Œå¹¶æœŸæœ›LLMèƒ½åšå¥½ï¼Œé‚£ä¹ˆä½ ä¸ä¼šå¾—åˆ°å¥½çš„ç»“æœã€‚æˆ‘è¯•è¿‡å¹¶å¤±è´¥äº†ï¼Œæ‰€ä»¥ä½ ä¸å¿…è‡ªå·±å°è¯•ã€‚ä»»ä½•æˆåŠŸçš„æœºå™¨å­¦ä¹ ç³»ç»Ÿæˆ–LLM/ç”Ÿæˆå¼AIç³»ç»Ÿéƒ½ä¾èµ–äºæ•°æ®å¤„ç†ã€‚è¿™æ˜¯ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œé€šå¸¸å æ®è¶…è¿‡80%çš„æ—¶é—´ã€‚å¦‚æœä½ çš„æ•°æ®å¤„ç†å¾—å½“ï¼Œé‚£ä¹ˆåç»­çš„æç¤ºå·¥ç¨‹å¯ä»¥ç¨åè¿›è¡Œã€‚ä¸è¦è¯•å›¾åœ¨æ•°æ®å‡†å¤‡é˜¶æ®µè¿›è¡Œæç¤ºå·¥ç¨‹ã€‚

**1. æ•°æ®æ‘„å–ï¼šç»˜åˆ¶æ•°æ®å…¨æ™¯**

é¦–å…ˆï¼Œæˆ‘éœ€è¦æŒæ¡æˆ‘ä»¬åºå¤§çš„æ•°æ®å…¨æ™¯ã€‚æˆ‘ä»¬çš„æ•°æ®å¹³å°ä½¿ç”¨AWS Glueä½œä¸ºä¸»è¦æ•°æ®ç›®å½•ï¼Œå› æ­¤Glueå§‹ç»ˆåŒ…å«è¡¨/æ•°æ®åº“/æ¨¡å¼çš„æœ€æ–°æ›´æ–°ã€‚è¿™ä¸€æ­¥è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä¸ºåç»­çš„ä¸€åˆ‡å¥ å®šäº†åŸºç¡€ã€‚

æˆ‘ç¼–å†™äº†ä¸€ä¸ªPythonè„šæœ¬ï¼Œé€šè¿‡AWS Glue APIæå–æˆ‘ä»¬æ‰€æœ‰æ•°æ®åº“å’Œè¡¨çš„ä¿¡æ¯ã€‚è¿™ä¸ä»…ä»…æ˜¯ç®€å•çš„æ•°æ®è½¬å‚¨â€”â€”æˆ‘å¿…é¡»ä»”ç»†æ„å»ºæå–çš„ä¿¡æ¯ï¼Œä»¥ä¾¿åœ¨é¡¹ç›®çš„åç»­é˜¶æ®µä½¿ç”¨ã€‚


```python
import boto3

session = boto3.Session(profile_name='<your_profile_name>')
glue_client = session.client('glue')
bedrock_runtime = session.client(service_name='bedrock-runtime')

def list_glue_tables(glue_client):
    raw_all_tables = []
    filtered_databases = ['<your_db1>','<your_db_2>','<your_db_3>']

    paginator = client.get_paginator('get_databases')
    for page in paginator.paginate():
        for database in page['DatabaseList']:
            if database['Name'] not in filtered_databases:
                continue

            table_paginator = client.get_paginator('get_tables')
            for table_page in table_paginator.paginate(DatabaseName=database['Name']):
                raw_all_tables.extend(table_page['TableList'])

    return raw_all_tables
```
è¯¥è„šæœ¬éå†æ¯ä¸ªæ•°æ®åº“ï¼Œç„¶åéå†è¿™äº›æ•°æ®åº“ä¸­çš„æ¯ä¸ªè¡¨ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œå¦‚è¡¨åã€åˆ—åå’Œç±»å‹ã€å­˜å‚¨ä½ç½®ä»¥åŠæœ€åæ›´æ–°æ—¶é—´æˆ³ã€‚è¿™ç§å…¨é¢çš„æ–¹æ³•ç¡®ä¿æ²¡æœ‰è¡¨è¢«é—æ¼ï¼Œä»è€Œä¸ºæˆ‘æä¾›äº†å®Œæ•´çš„æ•°æ®åœ°å›¾ã€‚


```python
def extract_schema(table):
    return {
        "DatabaseName": table['DatabaseName'],
        "TableName": table['Name'],
        "TableDescription": table.get('Description', ''),
        "Partition": table.get('PartitionKeys', None),
        "TableSchema": [
            {
                "Name": col['Name'],
                "Type": col['Type'],
                "Comment": col.get('Comment', '')
            } for col in table['StorageDescriptor']['Columns']
        ],
        "CreateTime": table.get('CreateTime', None),
        "UpdateTime": table.get('UpdateTime', None),
        "SourceSQL": table.get('ViewExpandedText', '')
    }

def process_table(table):
    print(f"Processing table {table['Name']}")
    schema = extract_schema(table)
    documentation = generate_documentation(schema) # find this function below
    table_name = f"{table['DatabaseName']}.{table['Name']}"
    save_documentation(table_name, documentation)
    print(f"===Documentation generated for {table['Name']}")
```

# 2. ä¸Šä¸‹æ–‡ä¸°å¯Œï¼šä¸ºåŸå§‹æ•°æ®å¢æ·»é£å‘³

åŸå§‹è¡¨æ¨¡å¼å°±åƒæœªè°ƒå‘³çš„é£Ÿç‰©â€”â€”åŠŸèƒ½æ€§å¼ºï¼Œä½†å¹¶ä¸ä»¤äººå…´å¥‹ã€‚æˆ‘éœ€è¦ä¸ºè¿™äº›æ•°æ®æ·»åŠ ä¸€äº›ä¸Šä¸‹æ–‡ï¼Œä¸€äº›è°ƒå‘³ã€‚è¿™å°±æ˜¯äº‹æƒ…å˜å¾—æœ‰è¶£çš„åœ°æ–¹ï¼Œä¹Ÿæ˜¯æˆ‘å¼€å§‹åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠ›é‡çš„åœ°æ–¹ã€‚

æˆ‘å¼€å‘äº†ä¸€ä¸ªåŸºäºLLMçš„ä¸°å¯Œè¿‡ç¨‹ï¼Œå®ƒå°†æå–æ¯ä¸ªè¡¨çš„åŸå§‹å…ƒæ•°æ®å¹¶ç”Ÿæˆæœ‰æ„ä¹‰çš„ä¸Šä¸‹æ–‡ã€‚è¿™ä¸ä»…ä»…æ˜¯é‡è¿°å…ƒæ•°æ®ä¸­å·²æœ‰çš„å†…å®¹â€”â€”æˆ‘å¸Œæœ›LLMèƒ½å¯¹è¡¨çš„ç›®çš„ã€ä¸å…¶ä»–è¡¨çš„å…³ç³»ä»¥åŠå®ƒå¯èƒ½å¦‚ä½•ä½¿ç”¨åšå‡ºæœ‰æ ¹æ®çš„çŒœæµ‹ã€‚


```python
def generate_documentation(schema):
    system_prompt = """
    You are an expert database and business developer specializing in <place holder for your purpose>
    Your task is to review database schemas and generate comprehensive documentation in JSON format. 
    Focus on providing insights relevant to the betting industry, including table purposes, column descriptions, 
    and potential use cases. Be concise yet informative, and ensure all output is in valid JSON format.
    """

    initial_user_prompt = f"""
    Please generate comprehensive documentation for the following database schema in JSON format only. 
    The documentation should include:
    1. A brief overview of the table's purpose and its role in <purpose>
    2. Detailed descriptions of each column, including its data type, purpose, and any relevant notes specific to the <your data platform>
    3. Any additional insights, best practices, or potential use cases for this table in the context of <your context>
    4. Comments on the creation and last update times of the table, if relevant to its usage or data freshness
    5. Generate at least 10 common queries that could be run against this table in the context <your context>

    Here's the schema:
    {json.dumps(schema, indent=2, cls=DateTimeEncoder)}

    Please provide the output in the following format:
    ```json
    {{
      "DatabaseName": "Name of the database",
      "TableName": "Name of the table",
      "TableDescription": "Brief overview of the table",
      "CreateTime": "Raw creation time of table",
      "UpdateTime": "Raw updated time of table",
      "Columns": [
        {{
          "name": "column_name",
          "type": "data_type",
          "description": "Detailed description and purpose of the column"
        }},
        // ... all other columns
      ],
      "AdditionalInsights": [
        "Insight 1",
        "Insight 2",
        // ... other insights
      ],
      "CommonQueries": [
            {
                "natural_language": "Nature english query",
                "sql_query": "Detail of SQL query",
            }
      ]
    }}
    ```

    If you need more space to complete the documentation, end your response with "[CONTINUE]" and I will prompt you to continue.
    """

    full_response = ""
    conversation_history = f"{system_prompt}\n\nuser: {initial_user_prompt}\n\nassistant: "

    while True:
        body = json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            "messages": [{"role": "user", "content": conversation_history}],
            "max_tokens": 8192,
            "temperature": 0,
        })

        response = bedrock_runtime.invoke_model(body=body, modelId=model_id)
        response_body = json.loads(response.get('body').read())
        current_response = response_body['content'][0]['text']
        full_response += current_response

        if response_body['stop_reason'] != 'max_tokens':
            break

        conversation_history += current_response
        conversation_history += "\n\nuser: Please continue the JSON documentation where you left off, maintaining the perspective of an expert in sports and racing betting platforms.\n\nassistant: "

    return full_response
```
è¿™ä¸€é˜¶æ®µçš„æç¤ºå·¥ç¨‹è‡³å…³é‡è¦ã€‚æˆ‘å¿…é¡»è®¾è®¡æç¤ºï¼Œä»¥å¼•å¯¼LLMæä¾›ï¼š

1. è¡¨åœ¨æˆ‘ä»¬ä¸šåŠ¡ä¸Šä¸‹æ–‡ä¸­å¯èƒ½ä»£è¡¨çš„è¯¦ç»†æè¿°ã€‚
2. è¡¨çš„æ½œåœ¨ç”¨ä¾‹ï¼Œè€ƒè™‘ä¸åŒéƒ¨é—¨å¯èƒ½å¦‚ä½•æŸ¥è¯¢å®ƒã€‚
3. ä¸å…¶ä»–è¡¨çš„å¯èƒ½å…³ç³»ï¼Œå¸®åŠ©ç»˜åˆ¶æˆ‘ä»¬çš„æ•°æ®æ¨¡å‹ã€‚
4. ä»»ä½•æ•°æ®è´¨é‡è€ƒè™‘ï¼Œä¾‹å¦‚æ½œåœ¨çš„ç©ºå€¼æˆ–æ•°æ®ç±»å‹ä¸ä¸€è‡´ã€‚
5. å¯¹äºå¤§å‹è¡¨çš„å»ºè®®åˆ†åŒºé”®ï¼Œè€ƒè™‘æŸ¥è¯¢ä¼˜åŒ–ã€‚
6. æ½œåœ¨çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œè¿™å¯¹åç»­çš„è¿æ¥æ“ä½œè‡³å…³é‡è¦ã€‚

**å…³é”®åœ¨äºï¼š**


> åœ¨å¤„ç†æ­¤å†…å®¹æ—¶ï¼ŒClaudeæ¨¡å‹é€šè¿‡Bedrockä»…æ”¯æŒæœ€å¤š4096ä¸ªè¾“å‡ºä»¤ç‰Œã€‚è¿™å¯¹äºå¤§å¤šæ•°ç”¨ä¾‹æ¥è¯´æ˜¯è¶³å¤Ÿçš„ï¼Œç„¶è€Œï¼Œå¯¹äºæŸäº›åŒ…å«è¶…è¿‡100åˆ—çš„ç‰¹æ®Šè¡¨ï¼Œå®ƒå¯èƒ½ä¼šå¯¼è‡´é”™è¯¯ã€‚ä¸ºäº†å¤„ç†è¿™ä¸ªé™åˆ¶ï¼Œæˆ‘ä»¬é¦–å…ˆæŸ¥çœ‹ç¬¬ä¸€ä¸ªè¾“å‡ºçš„å“åº”æ˜¯å¦åŒ…å«**max\_token**ä½œä¸º**stop\_reason**ã€‚å¦‚æœæ²¡æœ‰ï¼Œåˆ™ç»§ç»­è¯¥è¿‡ç¨‹ï¼Œä½†å¦‚æœå­˜åœ¨**max\_token**ï¼Œåˆ™éœ€è¦å°†ç°æœ‰å“åº”å‘é€ç»™LLMï¼Œå¹¶è°ƒæ•´æç¤ºä»¥è¯·æ±‚ä»ä¸Šä¸€æ­¥ç»§ç»­ç”Ÿæˆã€‚**è®°ä½ï¼šä¸Šä¸‹æ–‡ä»¤ç‰Œä¸º200kï¼Œè¾“å‡ºä»¤ç‰Œä»…ä¸º4096kã€‚**

æœ€ç»ˆè¾“å‡ºå¯èƒ½ç”±äºæŸäº›æ•…éšœè€Œæ— æ³•è§£æä¸ºJSONã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å°†æ­¤é”™è¯¯å†™å…¥txtæ–‡ä»¶ä»¥ä¾¿åç»­å®¡æŸ¥ã€‚


```python
def save_documentation(table_name, documentation):
    try:
        json_content = documentation.split("```json")[1].split("```")[0].strip()
        parsed_json = json.loads(json_content)

        with open(f"{folder}/table_json/{table_name}.json", "w") as f:
            json.dump(parsed_json, f, indent=2)
        print(f"===Documentation saved for {table_name}")
    except Exception as e:
        print(f"===Error parsing documentation for {table_name}: {str(e)}")
        with open(f"{folder}/{table_name}_doc_raw.txt", "w") as f:
            f.write(documentation)
        print(f"===Raw documentation saved for {table_name}")
```
è¿™æ˜¯å­˜å‚¨æ¨¡å¼çš„å‡½æ•°


```python
def process_table(table):
    print(f"Processing table {table['Name']}")
    schema = extract_schema(table)
    documentation = generate_documentation(schema)
    table_name = f"{table['DatabaseName']}.{table['Name']}"
    save_documentation(table_name, documentation)
    print(f"===Documentation generated for {table['Name']}")
```

# 3. åŒé‡ç´¢å¼•ï¼šåˆ›å»ºå®Œç¾çš„ç»“åˆ

æˆ‘å¼€å§‹ä½¿ç”¨æ™®é€šçš„å‘é‡ç´¢å¼•å’ŒåŸºæœ¬çš„å›ºå®šåˆ‡ç‰‡ï¼Œä½†ç»“æœå¾ˆç³Ÿç³•ï¼ŒSQLç”Ÿæˆå™¨ç»å¸¸è·å–é”™è¯¯çš„è¡¨åå’Œåˆ—åã€‚ç”±äºåˆ‡ç‰‡å°†å…¶åˆ‡å‰²æ‰ï¼Œå› æ­¤æ²¡æœ‰å®Œæ•´çš„ä¸Šä¸‹æ–‡ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘æ”¾å¼ƒäº†æ™®é€šçš„åˆ‡ç‰‡ç®—æ³•ï¼Œè½¬è€Œé‡‡ç”¨**å±‚æ¬¡åˆ‡ç‰‡**æ–¹æ³•ï¼Œå¹¶ç¨å¾®æ”¹å˜äº†æç¤ºã€‚è¿™äº§ç”Ÿäº†æ›´å¥½çš„å“åº”ï¼Œå¹¶è§£å†³äº†ç¬¬ä¸€ç§æ–¹æ³•çš„æ‰€æœ‰é—®é¢˜ã€‚

ä½†éšåï¼Œå‘é‡ç´¢å¼•å¿½ç•¥äº†ä¸€ä¸ªå…³é”®æ–¹é¢ï¼Œå³è¡¨ä¹‹é—´çš„å…³ç³»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä½¿ç”¨äº†çŸ¥è¯†å›¾è°±ï¼Œç»“æœéå¸¸å‡ºè‰²ã€‚

æ€»ä¹‹ï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§ç´¢å¼•æ–¹æ³•ï¼š

## å‘é‡ç´¢å¼•

å‘é‡ç´¢å¼•ä¸»è¦å…³æ³¨é€Ÿåº¦ã€‚æˆ‘ä½¿ç”¨ OpenSearch æ— æœåŠ¡å™¨ä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œå¹¶ä½¿ç”¨ **åˆ†å±‚åˆ‡åˆ†** ä½œä¸ºåˆ‡åˆ†ç®—æ³•ã€‚

## çŸ¥è¯†å›¾è°±

è™½ç„¶å‘é‡ç´¢å¼•ä¸ºæˆ‘ä»¬æä¾›äº†é€Ÿåº¦ï¼Œä½†çŸ¥è¯†å›¾è°±åˆ™æä¾›äº†æ·±åº¦ã€‚æˆ‘ä½¿ç”¨ NetworkX åˆ›å»ºäº†æˆ‘ä»¬æ•´ä¸ªæ•°æ®æ¨¡å‹çš„å›¾å½¢è¡¨ç¤ºã€‚æ¯ä¸ªè¡¨éƒ½æˆä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¾¹ç¼˜è¡¨ç¤ºè¡¨ä¹‹é—´çš„å…³ç³»ã€‚

å®šä¹‰è¿™äº›å…³ç³»çš„éš¾ç‚¹åœ¨äºã€‚æœ‰äº›å…³ç³»å¾ˆæ˜æ˜¾ï¼Œæ¯”å¦‚å¤–é”®å…³ç³»ï¼Œä½†å…¶ä»–å…³ç³»åˆ™éœ€è¦å¯¹æˆ‘ä»¬çš„æ•°æ®æ¨¡å‹æœ‰æ›´ç»†è‡´çš„ç†è§£ã€‚æˆ‘å®ç°äº†åŸºäºå‘½åçº¦å®šã€å…¬å…±å‰ç¼€å’Œç¬¬ 2 æ­¥ä¸­ä¸°å¯Œçš„å…ƒæ•°æ®æ¨æ–­å…³ç³»çš„é€»è¾‘ã€‚

è¿™ä¸ªçŸ¥è¯†å›¾è°±æˆä¸ºæˆ‘ä»¬ç³»ç»Ÿç†è§£å¤æ‚å¤šè¡¨æŸ¥è¯¢çš„åŸºç¡€ã€‚å®ƒä½¿ SQL Agent èƒ½å¤Ÿä»¥å…³ç³»å’Œè·¯å¾„çš„æ–¹å¼â€œæ€è€ƒâ€æ•°æ®ï¼Œç±»ä¼¼äºäººç±»æ•°æ®åˆ†æå¸ˆçš„æ–¹å¼ã€‚

# 4. é­”æ³•é¥®å“ï¼šå°†é—®é¢˜ç¿»è¯‘ä¸º SQL

ç°åœ¨ï¼Œè¿›å…¥æœ€é‡è¦çš„éƒ¨åˆ†ï¼ŒSQL Agent æœ¬èº«ã€‚æ­£å¦‚ä½ æ‰€çŸ¥é“çš„ï¼ŒLlamaIndex å§‹ç»ˆæ˜¯æˆ‘å¼€å‘ AI Agent æ—¶çš„é¦–é€‰ã€‚æˆ‘ä½¿ç”¨è¿‡ LangChain å’Œå…¶ä»–å¼€æºå·¥å…·ï¼Œè™½ç„¶ LangChain å‘å±•æˆç†Ÿä¸”æ‹¥æœ‰æ›´å¤§çš„ç¤¾åŒºæ”¯æŒï¼Œä½†æœ‰æ—¶å®ƒä¼šå¢åŠ ä¸å¿…è¦çš„å¤æ‚æ€§ã€‚

ä»¥ä¸‹æ˜¯ SQL Agent çš„å®ç°

## æç¤º

```python
def sql_agent_promt():
    return """
    You are an advanced AI assistant specialized in data analytics for <your domain database> with expert proficiency in Databricks Delta SQL. 
    Your primary role is to translate natural language queries into precise, executable SQL queries. 
    Follow these instructions meticulously:
    
    Core Responsibilities:
        - Always respond with an executable SQL query.
        - Do NOT execute SQL queries; only formulate them.
        - Utilize the vector database to access accurate schema information for all tables.
    
    Process:
    1. Understand User Input: 
        - Interpret the user's natural language query to comprehend their data requirements and objectives.
    2. Retrieve Relevant Tables:
        - Identify and retrieve the most relevant tables from the vector database that align with the user's query.
        - Continue this step until you find all necessary tables for the query.
    3. Verify Schema:
        - For each relevant table, retrieve and confirm the exact schema.
        - IMPORTANT: Pay special attention to column names, data types, and relationships between tables.
    4. Formulate SQL Query:
        - Construct a Databricks Delta SQL query using the confirmed schema information.
        - Ensure all table and column names used in the query exactly match the schema.
    5. Provide Professional Response
        - Draft the SQL query as a seasoned senior business analyst would, ensuring clarity, accuracy, and adherence to best practices.
    6. (Optional) Explanation
        - If requested, provide a detailed explanation of the SQL query and its logic.
        
    Response Format:
        1. Begin with the SQL query enclosed in triple backticks (```).
        2. Follow with a brief explanation of the query's purpose and how it addresses the user's request.
        3. Include a schema confirmation section, listing the tables and columns used.
    Guidelines:
        - Prioritize query accuracy and performance optimization.
        - Use clear and professional language in all responses.
        - Offer additional insights to enhance user understanding when appropriate.
    Error Handling:
        If you lack information or encounter ambiguity, use the following format:
        <clarification_request>
        I need additional information to formulate an accurate query. Could you please:
            - Provide more details about [specific aspect]?
            - Confirm if the following tables and columns are relevant: [list potential tables/columns]?
            - Clarify any specific time ranges, filters, or conditions for the data?
        </clarification_request>
        
    Schema Confirmation
        Before providing the final query, always confirm the schema:
        <schema_confirmation>
        I'll be using the following schema for this query:
        Table: [table_name1]
        Columns: [column1], [column2], ...
        Table: [table_name2]
        Columns: [column1], [column2], ...
        Are these the correct tables and columns for your query?
        </schema_confirmation>
        
        Example Response
        <give your example here>
        Remember to maintain a professional, clear, and helpful tone while engaging with users and formulating queries.        
    """
```

## è¯¥è¿‡ç¨‹å¦‚ä¸‹ï¼š

1. å½“ç”¨æˆ·æäº¤æŸ¥è¯¢æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨å‘é‡ç´¢å¼•å¿«é€Ÿè¯†åˆ«æ½œåœ¨ç›¸å…³çš„è¡¨å’Œåˆ—ã€‚
2. ç„¶åæˆ‘ä»¬å’¨è¯¢çŸ¥è¯†å›¾è°±ï¼Œä»¥äº†è§£è¿™äº›è¡¨ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ç¡®å®šå¯èƒ½éœ€è¦çš„å…¶ä»–è¡¨ï¼Œä»¥å›ç­”æŸ¥è¯¢ã€‚
3. åˆ©ç”¨è¿™äº›ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¸ºLLMæ„å»ºä¸€ä¸ªæç¤ºï¼Œå…¶ä¸­åŒ…æ‹¬ï¼š
* ç”¨æˆ·çš„åŸå§‹æŸ¥è¯¢
* ç›¸å…³è¡¨å’Œåˆ—çš„ä¿¡æ¯
* æ¥è‡ªæˆ‘ä»¬çš„çŸ¥è¯†å›¾è°±å’Œå‘é‡æ•°æ®åº“çš„ä¸Šä¸‹æ–‡ï¼Œå…³äºè¿™äº›è¡¨ä¹‹é—´çš„å…³ç³»
* æˆ‘ä»¬ç¼–ç çš„ä»»ä½•ç‰¹å®šä¸šåŠ¡è§„åˆ™æˆ–å¸¸è§å®è·µ

ç„¶åï¼ŒLLMæ ¹æ®è¿™äº›ä¿¡æ¯ç”ŸæˆSQLæŸ¥è¯¢ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡éªŒè¯æ­¥éª¤è¿è¡ŒæŸ¥è¯¢ï¼Œä»¥æ•æ‰ä»»ä½•æ˜æ˜¾çš„é”™è¯¯æˆ–ä½æ•ˆã€‚

## è¿™æ˜¯ä»£ç†çš„ä»£ç ï¼š

è®°ä½æˆ‘ä»¬ä¸Šé¢åˆ›å»ºçš„çŸ¥è¯†åº“ï¼Œæˆ‘ä»¬å°†å…¶ä½œä¸ºæ­¤ä»£ç†ä¸­çš„å·¥å…·ã€‚

```python
response_synthesizer = get_response_synthesizer(llm=llm)
query_engine = RetrieverQueryEngine(
    retriever=sql_knowledgebase,
    response_synthesizer=response_synthesizer,
)
query_engine_tools = [
    QueryEngineTool(
        query_engine=query_engine,
        metadata=ToolMetadata(
            name="database_retriever",
            description="Have access to data catalog, that have all details about databases, schemas, tables, table columns and its attribute along with description."
        ),
    ),
    ...... <second tool for knownledge graph>
]
agent_worker = FunctionCallingAgentWorker.from_tools(
    query_engine_tools,
    llm=llm,
    verbose=True,
    allow_parallel_tool_calls=True,
    system_prompt=sql_agent_promt()
)
agent = agent_worker.as_agent(memory=chat_memory)
```
æ­¤æ­¥éª¤çš„æç¤ºå·¥ç¨‹æ˜¯æ‰€æœ‰æ­¥éª¤ä¸­æœ€å…·æŒ‘æˆ˜æ€§çš„ã€‚æˆ‘å¿…é¡»åˆ›å»ºä¸€ä¸ªæç¤ºï¼Œä»¥æŒ‡å¯¼LLMç¼–å†™æ­£ç¡®ã€é«˜æ•ˆçš„SQLï¼ŒåŒæ—¶è§£é‡Šå…¶æ¨ç†ã€‚è¿™ä¸€è§£é‡Šç»„ä»¶å¯¹äºå»ºç«‹ç”¨æˆ·çš„ä¿¡ä»»å’Œå¸®åŠ©ä»–ä»¬ç†è§£ç”Ÿæˆçš„æŸ¥è¯¢è‡³å…³é‡è¦ã€‚

## ç»“æœï¼šä¸€ä¸ªæ°¸ä¸ä¼‘çœ çš„æ•°æ®å‘å¯¼

æˆ‘çš„SQLä»£ç†æœ€ç»ˆæˆä¸ºäº†æˆ‘ä»æœªçŸ¥é“è‡ªå·±éœ€è¦çš„MVPã€‚å°±åƒæ‹¥æœ‰ä¸€ä¸ª24/7çš„æ•°æ®ä¿¡ä½¿ï¼Œæ°¸è¿œä¸ä¼šæé”™ä½ çš„è®¢å•ã€‚

## é«˜çº§å¤šä»£ç†æ¶æ„ç°åœ¨

![](https://cdn-images-1.readmedium.com/v2/resize:fit:800/1*dNKG4zWdgRl5wGsiy-me9w.png)

å¦‚æ‚¨æ‰€è§ï¼Œæˆ‘ä»¬åœ¨çŸ©å½¢æ¡†ä¸­æœ‰å¦ä¸€ä¸ªä»£ç†ã€‚æˆ‘ä»¬ç°åœ¨æœ‰ä¸¤ä¸ªä»£ç†ï¼Œå®ƒä»¬ä¸æ–­ç›¸äº’äº¤æµï¼Œä»¥è§£å†³ç”¨æˆ·æŸ¥è¯¢ï¼Œåªè¦æŸ¥è¯¢ä¸ç”ŸæˆSQLæˆ–åŸºäºConfluenceæ–‡æ¡£çš„ä¸€èˆ¬é—®é¢˜æœ‰å…³ã€‚

# å­¦åˆ°çš„ç»éªŒ

åœ¨è¿™æ®µæ—…ç¨‹ä¸­ï¼Œæˆ‘å­¦åˆ°äº†ä¸€äº›å®è´µçš„ç»éªŒï¼Œæˆ‘è®¤ä¸ºè¿™äº›ç»éªŒå¯¹ä»»ä½•ä»äº‹ç±»ä¼¼é¡¹ç›®çš„äººéƒ½æœ‰ç›Šï¼š

1. **ä¸Šä¸‹æ–‡ä¸ºç‹**ï¼šç†è§£è¡¨çš„ä¸Šä¸‹æ–‡å’Œå…³ç³»æ˜¯ç”Ÿæˆå‡†ç¡®æŸ¥è¯¢çš„å…³é”®ã€‚
2. **åŸºäºå›¾çš„æ–¹å¼**ï¼šçŸ¥è¯†å›¾è°±æ–¹æ³•æ¯”æ™®é€šç´¢å¼•æ›´å¥½åœ°å¤„ç†å¤æ‚æŸ¥è¯¢ã€‚å®ƒä½¿ç³»ç»Ÿèƒ½å¤Ÿä»¥ä¸€ç§æ¥è¿‘äººç±»æ¨ç†çš„æ–¹å¼â€œæ€è€ƒâ€æ•°æ®å…³ç³»ã€‚
3. **æŒç»­å­¦ä¹ **ï¼šæˆ‘ä¸æ–­å°†æ–°æŸ¥è¯¢åé¦ˆåˆ°æˆ‘ä»¬çš„ç³»ç»Ÿä¸­ï¼Œä»¥æé«˜å…¶æ€§èƒ½ã€‚
4. **å¯è§£é‡Šæ€§è‡³å…³é‡è¦**ï¼šè®©ç³»ç»Ÿè§£é‡Šå…¶æ¨ç†å¯ä»¥å»ºç«‹ç”¨æˆ·çš„ä¿¡ä»»ï¼Œå¹¶å¸®åŠ©ä»–ä»¬äº†è§£æ•°æ®æ¨¡å‹ã€‚è¿™å°±åƒå¨å¸ˆè§£é‡Šå¤æ‚èœè‚´ä¸­çš„æˆåˆ†ä¸€æ ·ã€‚
5. **è¾¹ç¼˜æ¡ˆä¾‹æ˜¯ç”Ÿæ´»çš„è°ƒå‘³æ–™**ï¼šå¤„ç†è¾¹ç¼˜æ¡ˆä¾‹å’Œä¸å¯»å¸¸çš„æŸ¥è¯¢å¾€å¾€æ˜¯è·å¾—æœ€æœ‰è¶£è§è§£çš„åœ°æ–¹ã€‚è¿™è¿«ä½¿æˆ‘æ·±å…¥æ€è€ƒæˆ‘ä»¬çš„æ•°æ®æ¨¡å‹ä»¥åŠç”¨æˆ·å¦‚ä½•ä¸ä¹‹äº’åŠ¨ã€‚

# ç»“è®º

æˆ‘ä»ä¸€ä¸ªéšæ„çš„è¯„è®ºåˆ°ä¸€ä¸ªå¤æ‚çš„SQLä»£ç†çš„æ—…ç¨‹è¡¨æ˜ï¼Œå‡­å€Ÿæ­£ç¡®çš„æŠ€æœ¯ã€åˆ›é€ åŠ›å’Œä¸€ç‚¹å’–å•¡å› æ¿€å‘çš„çµæ„Ÿï¼Œæˆ‘ä»¬å¯ä»¥è§£å†³ç”šè‡³æœ€å¤æ‚çš„æ•°æ®æŒ‘æˆ˜ã€‚

æˆ‘åˆ›é€ çš„ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå·¥å…·ï¼›æˆ‘åˆ›é€ äº†ä¸€ç§å…¨æ–°çš„ä¸æ•°æ®äº’åŠ¨çš„æ–¹å¼ã€‚å®ƒæ­£åœ¨ä½¿æ¯ä¸ªå›¢é˜Ÿæˆå‘˜æˆä¸ºæ½œåœ¨çš„æ•°æ®ç¾é£Ÿå®¶ï¼Œä»è€Œå®ç°æ´å¯Ÿçš„æ°‘ä¸»åŒ–ã€‚

â¤ å¦‚æœæ‚¨è§‰å¾—è¿™ç¯‡æ–‡ç« å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæˆ‘éå¸¸æ„Ÿè°¢æ‚¨ç»™äºˆæˆ‘æŒå£°ã€‚è¿™å¯¹æˆ‘æ„ä¹‰é‡å¤§ï¼Œå¹¶è¯æ˜äº†æˆ‘çš„å·¥ä½œçš„ä»·å€¼ã€‚æ­¤å¤–ï¼Œæ‚¨å¯ä»¥ [è®¢é˜…æˆ‘çš„Substack](https://howaibuildthis.substack.com/)ï¼Œå› ä¸ºæˆ‘å°†åœ¨è¯¥é¢‘é“ä¸­æ¶µç›–æ›´æ·±å…¥çš„LLMå¼€å‘ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶ç•™è¨€ã€‚æˆ‘ä¼šå°½å¿«å›ç­”ã€‚

```python
æƒ³è¦è”ç³»ï¼Ÿ
å¦‚æœæ‚¨éœ€è¦è”ç³»ï¼Œè¯·éšæ—¶é€šè¿‡æˆ‘çš„ 
Twitteræˆ–LinkedInç»™æˆ‘å‘æ¶ˆæ¯ï¼Œå¹¶è®¢é˜…æˆ‘çš„Substackï¼Œå› ä¸ºæˆ‘å°†åœ¨æˆ‘çš„Substacké¢‘é“ä¸­è¦†ç›–
æ›´å¤šå­¦ä¹ å®è·µï¼Œå°¤å…¶æ˜¯æ·±å…¥å¼€å‘LLMçš„è·¯å¾„ã€‚
```

# å‚è€ƒæ–‡çŒ®

* æˆ‘æ‰€æœ‰å…³äºLLMçš„å‰æœŸåšå®¢æ–‡ç« ï¼š[https://readmedium.com/all-of-my-llm-and-rag-articles-c4b0848b0a21](https://readmedium.com/@ryanntk/all-of-my-llm-and-rag-articles-c4b0848b0a21)
* ä½¿ç”¨LlamaIndexçš„ä»£ç†æ–¹æ³•ï¼š<https://docs.llamaindex.ai/en/stable/use_cases/agents/>
* <https://aws.amazon.com/blogs/machine-learning/build-a-robust-text-to-sql-solution-generating-complex-queries-self-correcting-and-querying-diverse-data-sources/>
* <https://readmedium.com/how-we-built-text-to-sql-at-pinterest-30bad30dabff>
* <https://github.com/eosphoros-ai/Awesome-Text2SQL>
